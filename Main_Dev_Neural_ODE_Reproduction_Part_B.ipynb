{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8oIM_sA6DaW",
        "outputId": "f7e3f6a5-218c-47e3-8a05-a1154390edfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU model: Tesla T4\n",
            "GPU device count: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU model: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU device count: {torch.cuda.device_count()}\")\n",
        "else:\n",
        "    print(\"No GPU available.\")\n",
        "  "
      ],
      "id": "b8oIM_sA6DaW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39ad13b8"
      },
      "source": [
        "# Data Pre-processing\n",
        "\n",
        "First we will begin by pre-processing the data. In this case the sample data comes with the following features/columns: \n",
        "\n",
        "|   **Column**   |   **Desciption**   |\n",
        "|:-:\t         |:--\t              |\n",
        "|   STUD\t|   Study Number \t|\n",
        "|   DSFQ\t|   Dosing Frequency\t|\n",
        "|   PTNM\t|   Patient Number\t|\n",
        "|   CYCL\t|    Dosing Cycles\t|\n",
        "|   AMT\t|   Dosing Amounts\t|\n",
        "|   TIME\t|   Time in Hours Since the Experiment Began for one Individual\t|\n",
        "|   TFDS\t|   Time in Hours Since the Last Dosing|\n",
        "|   DV/PK_timeCourse\t|   The Observations of PK  \t|\n",
        "\n",
        "Let us first import the data into the notebook and observe these features of the dataset"
      ],
      "id": "39ad13b8"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ZSuIpPqC9pyK",
        "outputId": "1ff357ea-6b76-468e-f7ea-0c08e58df2ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bcb854bd-0d1a-4a8c-94d0-a22f123ca8fc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bcb854bd-0d1a-4a8c-94d0-a22f123ca8fc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sim_data.txt to sim_data.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        " \n",
        " \n",
        "uploaded = files.upload()"
      ],
      "id": "ZSuIpPqC9pyK"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "db700807",
        "outputId": "0a07ca67-b497-408b-96d0-a3fc2ddc5b6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        STUD   PTNM  DSFQ  CYCL    AMT    TIME    TFDS         DV\n",
              "0     1000.0    1.0   3.0   1.0  296.6     0.0     0.0  20.382000\n",
              "1     1000.0    1.0   3.0   1.0    0.0    24.0    24.0  73.148000\n",
              "2     1000.0    1.0   3.0   1.0    0.0   216.0   216.0  19.764000\n",
              "3     1000.0    1.0   3.0   1.0    0.0   504.0   504.0   3.219900\n",
              "4     1000.0    1.0   3.0   2.0  288.0   504.0     0.0   3.219900\n",
              "...      ...    ...   ...   ...    ...     ...     ...        ...\n",
              "5371  3000.0  200.0   3.0  15.0    0.0  7416.0   360.0   6.091200\n",
              "5372  3000.0  200.0   3.0  15.0    0.0  7584.0  7584.0   2.043100\n",
              "5373  3000.0  200.0   3.0  17.0  259.2  8064.0     0.0   0.090115\n",
              "5374  3000.0  200.0   3.0  17.0    0.0  8088.0    24.0  53.990000\n",
              "5375  3000.0  200.0   3.0  17.0    0.0  8256.0   192.0  17.255000\n",
              "\n",
              "[5376 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c40ec1cf-9e0c-4d12-aca9-fe084b87b510\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STUD</th>\n",
              "      <th>PTNM</th>\n",
              "      <th>DSFQ</th>\n",
              "      <th>CYCL</th>\n",
              "      <th>AMT</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TFDS</th>\n",
              "      <th>DV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.382000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>73.148000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>19.764000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>3.219900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.219900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5371</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7416.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>6.091200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>2.043100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5373</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>259.2</td>\n",
              "      <td>8064.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5374</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8088.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5375</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8256.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>17.255000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5376 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c40ec1cf-9e0c-4d12-aca9-fe084b87b510')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c40ec1cf-9e0c-4d12-aca9-fe084b87b510 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c40ec1cf-9e0c-4d12-aca9-fe084b87b510');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Importing required libraries for data pre-processing\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "\n",
        "#Reading the csv file with the data\n",
        "\n",
        "data_complete = pd.read_csv(io.BytesIO(uploaded['sim_data.txt']))\n",
        "data_complete\n",
        "\n",
        "\n",
        "# data_complete = pd.read_csv(\"/Users/rishabhgoel/Desktop/NeuralODE_Paper_Supplementary_Code/ExampleData/sim_data.csv\", na_values='.')\n",
        "\n",
        "# data_complete"
      ],
      "id": "db700807"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c33ce599"
      },
      "source": [
        "There are 5376 observations and 8 features that we are looking at. Now let us begin the pre-processing the data. \n",
        "\n",
        "Our sample data only has the relevant columns for the model. However, in the data we receive from patients there will be many more features so it is important for us to select the correct features. Thus, let us begin by creating a place holder for the features that are important to the model."
      ],
      "id": "c33ce599"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dcda0666"
      },
      "outputs": [],
      "source": [
        "#variable for colummns that we will eventually select from the raw dataset we receive\n",
        "\n",
        "select_cols = [\"STUD\", \"DSFQ\", \"PTNM\", \"CYCL\", \"AMT\", \"TIME\", \"TFDS\", \"DV\"]\n",
        "\n",
        "#Selecting the relevant columns from the dataframe\n",
        "\n",
        "data_complete = data_complete[select_cols]"
      ],
      "id": "dcda0666"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bef16820"
      },
      "source": [
        "We then start filtering data based on multiple parameters:\n",
        "    \n",
        "1. Dosing Cycle < 100"
      ],
      "id": "bef16820"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "b50237bc",
        "outputId": "d3ff4da5-ff7a-4228-9d0a-52b6f318c31b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        STUD  DSFQ   PTNM  CYCL    AMT    TIME    TFDS         DV\n",
              "0     1000.0   3.0    1.0   1.0  296.6     0.0     0.0  20.382000\n",
              "1     1000.0   3.0    1.0   1.0    0.0    24.0    24.0  73.148000\n",
              "2     1000.0   3.0    1.0   1.0    0.0   216.0   216.0  19.764000\n",
              "3     1000.0   3.0    1.0   1.0    0.0   504.0   504.0   3.219900\n",
              "4     1000.0   3.0    1.0   2.0  288.0   504.0     0.0   3.219900\n",
              "...      ...   ...    ...   ...    ...     ...     ...        ...\n",
              "5371  3000.0   3.0  200.0  15.0    0.0  7416.0   360.0   6.091200\n",
              "5372  3000.0   3.0  200.0  15.0    0.0  7584.0  7584.0   2.043100\n",
              "5373  3000.0   3.0  200.0  17.0  259.2  8064.0     0.0   0.090115\n",
              "5374  3000.0   3.0  200.0  17.0    0.0  8088.0    24.0  53.990000\n",
              "5375  3000.0   3.0  200.0  17.0    0.0  8256.0   192.0  17.255000\n",
              "\n",
              "[5376 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac79d7b9-76fd-4da7-a555-5574eea4b64f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STUD</th>\n",
              "      <th>DSFQ</th>\n",
              "      <th>PTNM</th>\n",
              "      <th>CYCL</th>\n",
              "      <th>AMT</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TFDS</th>\n",
              "      <th>DV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.382000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>73.148000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>19.764000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>3.219900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.219900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5371</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7416.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>6.091200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>2.043100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5373</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>259.2</td>\n",
              "      <td>8064.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5374</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8088.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5375</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8256.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>17.255000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5376 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac79d7b9-76fd-4da7-a555-5574eea4b64f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac79d7b9-76fd-4da7-a555-5574eea4b64f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac79d7b9-76fd-4da7-a555-5574eea4b64f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# filtering for only the rows in the dataframe with a dosing cycle less than 100\n",
        "\n",
        "data_complete = data_complete[data_complete.CYCL < 100]\n",
        "data_complete"
      ],
      "id": "b50237bc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e142ba2f"
      },
      "source": [
        "We then convert the \"PTNM\" column to an integer type using the astype() method, and then using the map() method to apply a format string to each value in the column. The format string \"{:05d}\" specifies that each value should be formatted as a zero-padded integer with a width of 5 digits.\n",
        "\n",
        "For example, if the \"PTNM\" column originally contained the values [1, 10, 100, 1000], after this line of code is executed, the \"PTNM\" column would contain the values ['00001', '00010', '00100', '01000'].\n",
        "\n",
        "This line of code is useful for standardizing the format of the values in the \"PTNM\" column, which can make it easier to perform operations on the column and to compare values within the column. It can also be useful for preparing the data for downstream model applications that require the data to be in a particular format."
      ],
      "id": "e142ba2f"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "d16386ac",
        "outputId": "3cdce52e-5fe5-4105-a009-fcf4ea5ccd1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        STUD  DSFQ   PTNM  CYCL    AMT    TIME    TFDS         DV\n",
              "0     1000.0   3.0  00001   1.0  296.6     0.0     0.0  20.382000\n",
              "1     1000.0   3.0  00001   1.0    0.0    24.0    24.0  73.148000\n",
              "2     1000.0   3.0  00001   1.0    0.0   216.0   216.0  19.764000\n",
              "3     1000.0   3.0  00001   1.0    0.0   504.0   504.0   3.219900\n",
              "4     1000.0   3.0  00001   2.0  288.0   504.0     0.0   3.219900\n",
              "...      ...   ...    ...   ...    ...     ...     ...        ...\n",
              "5371  3000.0   3.0  00200  15.0    0.0  7416.0   360.0   6.091200\n",
              "5372  3000.0   3.0  00200  15.0    0.0  7584.0  7584.0   2.043100\n",
              "5373  3000.0   3.0  00200  17.0  259.2  8064.0     0.0   0.090115\n",
              "5374  3000.0   3.0  00200  17.0    0.0  8088.0    24.0  53.990000\n",
              "5375  3000.0   3.0  00200  17.0    0.0  8256.0   192.0  17.255000\n",
              "\n",
              "[5376 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-753a3a27-8e52-4bf0-876f-2147efb847ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STUD</th>\n",
              "      <th>DSFQ</th>\n",
              "      <th>PTNM</th>\n",
              "      <th>CYCL</th>\n",
              "      <th>AMT</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TFDS</th>\n",
              "      <th>DV</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.382000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>73.148000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>19.764000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>3.219900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>2.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.219900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5371</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7416.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>6.091200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>2.043100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5373</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>259.2</td>\n",
              "      <td>8064.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5374</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8088.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5375</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8256.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>17.255000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5376 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-753a3a27-8e52-4bf0-876f-2147efb847ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-753a3a27-8e52-4bf0-876f-2147efb847ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-753a3a27-8e52-4bf0-876f-2147efb847ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# formatting Patient Number for Unique Identifier\n",
        "data_complete[\"PTNM\"] = data_complete[\"PTNM\"].astype(\"int\").map(\"{:05d}\".format)\n",
        "data_complete"
      ],
      "id": "d16386ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30472bad"
      },
      "source": [
        "Now we create a new column called \"ID\" in the pandas DataFrame data_complete. The \"ID\" column is being created by concatenating two existing columns in ```data_complete```: \"STUD\" and \"PTNM\".\n",
        "\n",
        "First, the \"STUD\" column is being converted to an integer data type using the ```astype()``` method with the argument \"int\". Then, the \"STUD\" column is being converted to a string data type using the ```astype()``` method with the argument \"str\". This ensures that the values in the \"STUD\" column are in string format.\n",
        "\n",
        "Next, the values in the \"STUD\" and \"PTNM\" columns are being concatenated using the + operator, which joins the two strings together. This creates a new string for each row in the DataFrame, which is assigned to the \"ID\" column.\n",
        "\n",
        "For example, if the \"STUD\" column contained the values ['100', '101', '102', '103'] and the \"PTNM\" column contained the values ['00001', '00010', '00100', '01000'], then after this line of code is executed, the \"ID\" column would contain the values ['10000001', '10100010', '10200100', '10301000'].\n",
        "\n",
        "This line of code is useful for creating a unique identifier for each row in the DataFrame based on the values in the \"STUD\" and \"PTNM\" columns. This can be useful for identifying and tracking individual records, as well as for linking data across multiple datasets."
      ],
      "id": "30472bad"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7694284c",
        "outputId": "cc202664-fdf9-4e92-e326-5e58bf317aae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        STUD  DSFQ   PTNM  CYCL    AMT    TIME    TFDS         DV         ID\n",
              "0     1000.0   3.0  00001   1.0  296.6     0.0     0.0  20.382000  100000001\n",
              "1     1000.0   3.0  00001   1.0    0.0    24.0    24.0  73.148000  100000001\n",
              "2     1000.0   3.0  00001   1.0    0.0   216.0   216.0  19.764000  100000001\n",
              "3     1000.0   3.0  00001   1.0    0.0   504.0   504.0   3.219900  100000001\n",
              "4     1000.0   3.0  00001   2.0  288.0   504.0     0.0   3.219900  100000001\n",
              "...      ...   ...    ...   ...    ...     ...     ...        ...        ...\n",
              "5371  3000.0   3.0  00200  15.0    0.0  7416.0   360.0   6.091200  300000200\n",
              "5372  3000.0   3.0  00200  15.0    0.0  7584.0  7584.0   2.043100  300000200\n",
              "5373  3000.0   3.0  00200  17.0  259.2  8064.0     0.0   0.090115  300000200\n",
              "5374  3000.0   3.0  00200  17.0    0.0  8088.0    24.0  53.990000  300000200\n",
              "5375  3000.0   3.0  00200  17.0    0.0  8256.0   192.0  17.255000  300000200\n",
              "\n",
              "[5376 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de3d474c-b502-418e-893f-6e3bb5f7c705\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STUD</th>\n",
              "      <th>DSFQ</th>\n",
              "      <th>PTNM</th>\n",
              "      <th>CYCL</th>\n",
              "      <th>AMT</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TFDS</th>\n",
              "      <th>DV</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.382000</td>\n",
              "      <td>100000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>73.148000</td>\n",
              "      <td>100000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>19.764000</td>\n",
              "      <td>100000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>3.219900</td>\n",
              "      <td>100000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>2.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.219900</td>\n",
              "      <td>100000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5371</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7416.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>6.091200</td>\n",
              "      <td>300000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>2.043100</td>\n",
              "      <td>300000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5373</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>259.2</td>\n",
              "      <td>8064.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090115</td>\n",
              "      <td>300000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5374</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8088.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.990000</td>\n",
              "      <td>300000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5375</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8256.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>17.255000</td>\n",
              "      <td>300000200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5376 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de3d474c-b502-418e-893f-6e3bb5f7c705')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de3d474c-b502-418e-893f-6e3bb5f7c705 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de3d474c-b502-418e-893f-6e3bb5f7c705');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Creating a unique identifier column, 'ID', and formatting it based on Patient Number and Study Number\n",
        "data_complete[\"ID\"] = data_complete[\"STUD\"].astype(\"int\").astype(\"str\") + data_complete[\"PTNM\"]\n",
        "data_complete"
      ],
      "id": "7694284c"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "85ba9f4f",
        "outputId": "5ee52d54-e25f-4405-c3a9-a0e0a1362ee5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        STUD  DSFQ   PTNM  CYCL    AMT    TIME    TFDS         DV         ID\n",
              "0     1000.0   3.0  00001   1.0  296.6     0.0     0.0  20.382000  100000001\n",
              "1     1000.0   3.0  00001   1.0    0.0    24.0    24.0  73.148000  100000001\n",
              "2     1000.0   3.0  00001   1.0    0.0   216.0   216.0  19.764000  100000001\n",
              "3     1000.0   3.0  00001   1.0    0.0   504.0   504.0   3.219900  100000001\n",
              "4     1000.0   3.0  00001   2.0  288.0   504.0     0.0   3.219900  100000001\n",
              "...      ...   ...    ...   ...    ...     ...     ...        ...        ...\n",
              "5371  3000.0   3.0  00200  15.0    0.0  7416.0   360.0   6.091200  300000200\n",
              "5372  3000.0   3.0  00200  15.0    0.0  7584.0  7584.0   2.043100  300000200\n",
              "5373  3000.0   3.0  00200  17.0  259.2  8064.0     0.0   0.090115  300000200\n",
              "5374  3000.0   3.0  00200  17.0    0.0  8088.0    24.0  53.990000  300000200\n",
              "5375  3000.0   3.0  00200  17.0    0.0  8256.0   192.0  17.255000  300000200\n",
              "\n",
              "[5376 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5aa44e74-902d-4803-b9d1-f77b22210389\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STUD</th>\n",
              "      <th>DSFQ</th>\n",
              "      <th>PTNM</th>\n",
              "      <th>CYCL</th>\n",
              "      <th>AMT</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TFDS</th>\n",
              "      <th>DV</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.382000</td>\n",
              "      <td>100000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>73.148000</td>\n",
              "      <td>100000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>19.764000</td>\n",
              "      <td>100000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>3.219900</td>\n",
              "      <td>100000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>2.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.219900</td>\n",
              "      <td>100000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5371</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7416.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>6.091200</td>\n",
              "      <td>300000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>2.043100</td>\n",
              "      <td>300000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5373</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>259.2</td>\n",
              "      <td>8064.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090115</td>\n",
              "      <td>300000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5374</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8088.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.990000</td>\n",
              "      <td>300000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5375</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8256.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>17.255000</td>\n",
              "      <td>300000200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5376 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5aa44e74-902d-4803-b9d1-f77b22210389')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5aa44e74-902d-4803-b9d1-f77b22210389 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5aa44e74-902d-4803-b9d1-f77b22210389');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Creating a dataframe with the maximum time for each patient in each study (Essentially presenting the time of the last observed dose)\n",
        "time_summary = data_complete[[\"ID\", \"TIME\"]].groupby(\"ID\").max().reset_index()\n",
        "\n",
        "# Creating a new dataframe with only the IDs for patients with a time of the last observed dose greater than 0 (eliminating errors/outliers)\n",
        "selected_ptnms = time_summary[time_summary.TIME > 0].ID\n",
        "\n",
        "# Only selecting IDs with the last observed dose greater than 0 in our main table called data_complete\n",
        "data_complete = data_complete[data_complete.ID.isin(selected_ptnms)]\n",
        "data_complete"
      ],
      "id": "85ba9f4f"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "a6ca18dd",
        "outputId": "c97b3283-4b06-47d5-b942-73e1df59ce71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        STUD  DSFQ   PTNM  CYCL    AMT    TIME    TFDS  PK_timeCourse  \\\n",
              "0     1000.0   3.0  00001   1.0  296.6     0.0     0.0      20.382000   \n",
              "1     1000.0   3.0  00001   1.0    0.0    24.0    24.0      73.148000   \n",
              "2     1000.0   3.0  00001   1.0    0.0   216.0   216.0      19.764000   \n",
              "3     1000.0   3.0  00001   1.0    0.0   504.0   504.0       3.219900   \n",
              "4     1000.0   3.0  00001   2.0  288.0   504.0     0.0       3.219900   \n",
              "...      ...   ...    ...   ...    ...     ...     ...            ...   \n",
              "5371  3000.0   3.0  00200  15.0    0.0  7416.0   360.0       6.091200   \n",
              "5372  3000.0   3.0  00200  15.0    0.0  7584.0  7584.0       2.043100   \n",
              "5373  3000.0   3.0  00200  17.0  259.2  8064.0     0.0       0.090115   \n",
              "5374  3000.0   3.0  00200  17.0    0.0  8088.0    24.0      53.990000   \n",
              "5375  3000.0   3.0  00200  17.0    0.0  8256.0   192.0      17.255000   \n",
              "\n",
              "             ID  PK_round1  \n",
              "0     100000001     20.382  \n",
              "1     100000001     73.148  \n",
              "2     100000001     19.764  \n",
              "3     100000001      0.000  \n",
              "4     100000001      0.000  \n",
              "...         ...        ...  \n",
              "5371  300000200      0.000  \n",
              "5372  300000200      0.000  \n",
              "5373  300000200      0.000  \n",
              "5374  300000200      0.000  \n",
              "5375  300000200      0.000  \n",
              "\n",
              "[5376 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ede1e61-cb19-48f5-b01b-9dad3fdceca8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STUD</th>\n",
              "      <th>DSFQ</th>\n",
              "      <th>PTNM</th>\n",
              "      <th>CYCL</th>\n",
              "      <th>AMT</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TFDS</th>\n",
              "      <th>PK_timeCourse</th>\n",
              "      <th>ID</th>\n",
              "      <th>PK_round1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.382000</td>\n",
              "      <td>100000001</td>\n",
              "      <td>20.382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>73.148000</td>\n",
              "      <td>100000001</td>\n",
              "      <td>73.148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>19.764000</td>\n",
              "      <td>100000001</td>\n",
              "      <td>19.764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>3.219900</td>\n",
              "      <td>100000001</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>2.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.219900</td>\n",
              "      <td>100000001</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5371</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7416.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>6.091200</td>\n",
              "      <td>300000200</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>2.043100</td>\n",
              "      <td>300000200</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5373</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>259.2</td>\n",
              "      <td>8064.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090115</td>\n",
              "      <td>300000200</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5374</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8088.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.990000</td>\n",
              "      <td>300000200</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5375</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8256.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>17.255000</td>\n",
              "      <td>300000200</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5376 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ede1e61-cb19-48f5-b01b-9dad3fdceca8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ede1e61-cb19-48f5-b01b-9dad3fdceca8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ede1e61-cb19-48f5-b01b-9dad3fdceca8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# filling in missing values in the \"AMT\" column with Dosing Amounts equal to 0\n",
        "data_complete[\"AMT\"] = data_complete[\"AMT\"].fillna(0)\n",
        "\n",
        "\n",
        "#Renaming the column DV to PK_timeCourse so that the name is more self-explanatory\n",
        "data_complete = data_complete.rename(columns={\"DV\": \"PK_timeCourse\"})\n",
        "\n",
        "\n",
        "# Duplicating PK_timeCourse column to make changes to it separately\n",
        "data_complete[\"PK_round1\"] = data_complete[\"PK_timeCourse\"]\n",
        "\n",
        "# Changing the PK_round1 such that if the dosing frequency is once weekly and the time of the last \n",
        "# observed dose is greater than 168hrs the PK for round 1 is zero. Similarly, if the dosing frequency \n",
        "# is once weekly and the time of the last observed dose is greater than 504hrs the PK for round 1 is zero\n",
        "data_complete.loc[(data_complete.DSFQ == 1) & (data_complete.TIME >= 168), \"PK_round1\"] = 0\n",
        "data_complete.loc[(data_complete.DSFQ == 3) & (data_complete.TIME >= 504), \"PK_round1\"] = 0\n",
        "\n",
        "# filling in missing values in the \"PK_round1\" column with 0\n",
        "data_complete[\"PK_round1\"] = data_complete[\"PK_round1\"].fillna(0)\n",
        "\n",
        "# filling in missing values in the \"PK_timeCourse\" column with -1\n",
        "data_complete[\"PK_timeCourse\"] = data_complete[\"PK_timeCourse\"].fillna(-1)\n",
        "data_complete"
      ],
      "id": "a6ca18dd"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1d6f5219",
        "outputId": "724b0946-2147-4f5d-cc75-d94929cb616f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        STUD  DSFQ   PTNM  CYCL    AMT    TIME    TFDS  PK_timeCourse  \\\n",
              "0     1000.0   3.0  00001   1.0  296.6     0.0     0.0      20.382000   \n",
              "1     1000.0   3.0  00001   1.0    0.0    24.0    24.0      73.148000   \n",
              "2     1000.0   3.0  00001   1.0    0.0   216.0   216.0      19.764000   \n",
              "3     1000.0   3.0  00001   1.0  288.0   504.0   504.0       3.219900   \n",
              "5     1000.0   3.0  00001   2.0    0.0   696.0   192.0      23.210000   \n",
              "...      ...   ...    ...   ...    ...     ...     ...            ...   \n",
              "5371  3000.0   3.0  00200  15.0    0.0  7416.0   360.0       6.091200   \n",
              "5372  3000.0   3.0  00200  15.0    0.0  7584.0  7584.0       2.043100   \n",
              "5373  3000.0   3.0  00200  17.0  259.2  8064.0     0.0       0.090115   \n",
              "5374  3000.0   3.0  00200  17.0    0.0  8088.0    24.0      53.990000   \n",
              "5375  3000.0   3.0  00200  17.0    0.0  8256.0   192.0      17.255000   \n",
              "\n",
              "             ID  PK_round1  \n",
              "0     100000001     20.382  \n",
              "1     100000001     73.148  \n",
              "2     100000001     19.764  \n",
              "3     100000001      0.000  \n",
              "5     100000001      0.000  \n",
              "...         ...        ...  \n",
              "5371  300000200      0.000  \n",
              "5372  300000200      0.000  \n",
              "5373  300000200      0.000  \n",
              "5374  300000200      0.000  \n",
              "5375  300000200      0.000  \n",
              "\n",
              "[5137 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa9c2077-d83f-4c82-89f3-9f2940715c37\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STUD</th>\n",
              "      <th>DSFQ</th>\n",
              "      <th>PTNM</th>\n",
              "      <th>CYCL</th>\n",
              "      <th>AMT</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TFDS</th>\n",
              "      <th>PK_timeCourse</th>\n",
              "      <th>ID</th>\n",
              "      <th>PK_round1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.382000</td>\n",
              "      <td>100000001</td>\n",
              "      <td>20.382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>73.148000</td>\n",
              "      <td>100000001</td>\n",
              "      <td>73.148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>19.764000</td>\n",
              "      <td>100000001</td>\n",
              "      <td>19.764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>3.219900</td>\n",
              "      <td>100000001</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>696.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>23.210000</td>\n",
              "      <td>100000001</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5371</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7416.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>6.091200</td>\n",
              "      <td>300000200</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>7584.0</td>\n",
              "      <td>2.043100</td>\n",
              "      <td>300000200</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5373</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>259.2</td>\n",
              "      <td>8064.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.090115</td>\n",
              "      <td>300000200</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5374</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8088.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.990000</td>\n",
              "      <td>300000200</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5375</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00200</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8256.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>17.255000</td>\n",
              "      <td>300000200</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5137 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa9c2077-d83f-4c82-89f3-9f2940715c37')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa9c2077-d83f-4c82-89f3-9f2940715c37 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa9c2077-d83f-4c82-89f3-9f2940715c37');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Removing rows where the \"AMT\" column is 0 and the \"TIME\" column is also 0.\n",
        "data_complete = data_complete[~((data_complete.AMT == 0) & (data_complete.TIME == 0))]\n",
        "\n",
        "# Keeping the last row for all patients with duplicate values for time in hours \n",
        "data_complete.loc[data_complete[[\"PTNM\", \"TIME\"]].duplicated(keep=\"last\"), \"AMT\"] = \\\n",
        "    data_complete.loc[data_complete[[\"PTNM\", \"TIME\"]].duplicated(keep=\"first\"), \"AMT\"].values\n",
        "\n",
        "# Keeping the first row for all observations with duplicate values for all features apart from patient and time in hours \n",
        "data_complete = data_complete[~data_complete[[\"PTNM\", \"TIME\"]].duplicated(keep=\"first\")]\n",
        "\n",
        "data_complete"
      ],
      "id": "1d6f5219"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66c13129"
      },
      "source": [
        "# Splitting Data\n",
        "\n",
        "Now, we want to be able to split our data into training, validation, and test groups. This is a method of ensuring that we can hypertune our model without any biases and have the most robust version of our model in the final output.\n",
        "\n",
        "We begin by defining a function called ```data_split``` that we will use eventually to split our data in a customized way. Arguments for the function include a dataframe (```df```), a column (```on_col```), a list of columns to be saved in the output dataframes (```save_cols```), the seed of the split (```seed```), and the proportion of the data that will go into the test set (```test_size```)."
      ],
      "id": "66c13129"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "815e1d88"
      },
      "outputs": [],
      "source": [
        "#Importing the necessary library for splitting the data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Defining the function called data_split which takes in a dataframe, a column name (likely with patient identifiers), \n",
        "# and a default test size of 20%. \n",
        "def data_split(df, on_col, save_cols=None, seed=2020, test_size=0.2):\n",
        "    \n",
        "    #Setting the default save_cols to all columns of the dataset\n",
        "    if not save_cols:\n",
        "        save_cols = df.columns.values\n",
        "\n",
        "    #Setting a variable called target which contains all the unique values of a certain column. \n",
        "    #This variable will be helpful to split the unique patients into train and test later in the code.\n",
        "    target = df[on_col].unique()\n",
        "    \n",
        "    #Setting the train variable to contain the random unique patients numbers of 80% of the patients \n",
        "    #while the remaining 20% is the allocated to the test variable\n",
        "    train, test = train_test_split(target, random_state=seed, test_size=test_size, shuffle=True)\n",
        "    \n",
        "    #Creating the train and test dataframes (train_df and test_df). The training dataframe (train_df) includes all rows of \n",
        "    #patients in the train variable (train). The test dataframe (test_df) includes all rows of remaining patients (test).\n",
        "    train_df = df[df[on_col].isin(train)]\n",
        "    test_df = df[df[on_col].isin(test)]\n",
        "\n",
        "    #Returning  \n",
        "    return train_df[save_cols], test_df[save_cols]"
      ],
      "id": "815e1d88"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ab082c5"
      },
      "source": [
        "We then build the code for the ```main``` that takes in our input data uses the helper function that we created above ```data_split()``` to split our data into training, validation, and test sets.\n",
        "\n",
        "Next, the main adds a specific portion of the test set into the training and validation sets that we created above. \n",
        "\n",
        "Then, the main performs an augmentation that splits each patient into three groups. The main purpose of this augmentation in my opinion is to eliminate the problems associated with translating the results from one dosing regimen to the next.\n"
      ],
      "id": "1ab082c5"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "56c9f36e"
      },
      "outputs": [],
      "source": [
        "def datasplitter(data, fold, model):\n",
        "  train, test = data_split(data, \"PTNM\", seed=1329+fold, test_size=0.2)\n",
        "  train, validate = data_split(train, \"PTNM\", seed=1329+fold+model, test_size=0.2)\n",
        "  train = pd.concat([train, test[test.TIME < 168]], ignore_index=True)\n",
        "  validate = pd.concat([validate, test[test.TIME < 168]], ignore_index=True)\n",
        "\n",
        "  # James' augmentation\n",
        "  # Deep learning is prone to overfitting, and they applied augmentation to prevent overfitting. We applied \n",
        "  # timewise truncation to increase the number of training examples. For each training example, in addition to the \n",
        "  # original example, we also truncated the examples at 1008 hr, 1512 hr, and 2016 hr and generated and added a \n",
        "  # set of new examples to the training examples.\n",
        "\n",
        "  augment_data = pd.DataFrame(columns=train.columns)\n",
        "\n",
        "  for ptnm in train.PTNM.unique():\n",
        "      df = train[(train.PTNM == ptnm) & (train.TIME <= 2 * 21 * 24) & (train.TIME >= 0)]\n",
        "      df[\"PTNM\"] = df[\"PTNM\"] + str(0.1)\n",
        "      augment_data = pd.concat([augment_data, df], ignore_index=True)\n",
        "\n",
        "      df = train[(train.PTNM == ptnm) & (train.TIME <= 3 * 21 * 24) & (train.TIME >= 0)]\n",
        "      df[\"PTNM\"] = df[\"PTNM\"] + str(0.2)\n",
        "      augment_data = pd.concat([augment_data, df], ignore_index=True)\n",
        "\n",
        "      df = train[(train.PTNM == ptnm) & (train.TIME <= 4 * 21 * 24) & (train.TIME >= 0)]\n",
        "      df[\"PTNM\"] = df[\"PTNM\"] + str(0.3)\n",
        "      augment_data = pd.concat([augment_data, df], ignore_index=True)\n",
        "\n",
        "  train = pd.concat([train, augment_data], ignore_index=True).reset_index(drop=True)\n",
        "  \n",
        "\n",
        "  train.to_csv(\"train.csv\", index=False) \n",
        "  validate.to_csv(\"validate.csv\", index=False)\n",
        "  test.to_csv(\"test.csv\", index=False)\n",
        "  return train, validate, test"
      ],
      "id": "56c9f36e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDy7JPDMdXej"
      },
      "outputs": [],
      "source": [
        "# for fold in np.arange(1,6):\n",
        "#   for model in np.arange(1,6):\n",
        "#      train, validate, test = datasplitter(data_complete, fold, model)\n",
        "#     #  runtest()\n",
        "#      print(fold, model)"
      ],
      "id": "fDy7JPDMdXej"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5o1WUUWODiNt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def generate_interp(ptnm):\n",
        "    test = pd.read_csv(\"test.csv\")\n",
        "    subset = test[test.PTNM == ptnm]\n",
        "    interp_times = pd.DataFrame({\"TIME\": np.linspace(subset.loc[subset.TIME >= 168, \"TIME\"].values[:-1], \\\n",
        "                             subset.loc[subset.TIME >= 168, \"TIME\"].values[1:], 6, endpoint=False).flatten(\"F\")})\n",
        "    subset = pd.merge(subset, interp_times, how=\"outer\", on=\"TIME\").sort_values(by=\"TIME\").reset_index(drop=True)\n",
        "    subset[\"AMT\"] = subset[\"AMT\"].fillna(0)\n",
        "    subset[\"PK_round1\"] = subset[\"PK_round1\"].fillna(0)\n",
        "    subset[\"PTNM\"] = subset[\"PTNM\"].fillna(method=\"ffill\")\n",
        "    subset[\"DSFQ\"] = subset[\"DSFQ\"].fillna(1)\n",
        "    subset[\"CYCL\"] = subset[\"CYCL\"].fillna(method=\"ffill\")\n",
        "    subset[\"PK_timeCourse\"] = subset[\"PK_timeCourse\"].fillna(-10) \n",
        "    \n",
        "    start_time = 0\n",
        "    for idx, feature in subset.iterrows():\n",
        "\n",
        "        if feature[\"AMT\"] > 0:\n",
        "            start_time = feature[\"TIME\"]\n",
        "            continue\n",
        "\n",
        "        subset.loc[idx, \"TFDS\"] = subset.loc[idx, \"TIME\"] - start_time\n",
        "\n",
        "    return subset.drop(columns=[\"STUD\", \"ID\"])"
      ],
      "id": "5o1WUUWODiNt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmsRmM-EtIh2"
      },
      "source": [
        "#ENDDDDDDD\n"
      ],
      "id": "bmsRmM-EtIh2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnTC5e1r2cpY"
      },
      "source": [
        "# BRINGING IN THE ENTIRE UTILS.PY FILE"
      ],
      "id": "wnTC5e1r2cpY"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28rTipF9DlsY",
        "outputId": "82ca08f5-db84-4fc1-d41e-b581d5c81dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.3-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from torchdiffeq) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from torchdiffeq) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.3.0->torchdiffeq) (4.5.0)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdiffeq\n",
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from torchdiffeq import odeint_adjoint as odeint\n",
        "\n",
        "\n",
        "def makedirs(dirname):\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "\n",
        "\n",
        "def get_device(tensor):\n",
        "    device = torch.device(\"cuda\")\n",
        "    if tensor.is_cuda:\n",
        "        device = tensor.get_device()\n",
        "    return device\n",
        "\n",
        "\n",
        "def load_model(ckpt_path, encoder=None, ode_func=None, classifier=None, device=\"cuda\"):\n",
        "    if not os.path.exists(ckpt_path):\n",
        "        raise Exception(\"Checkpoint \" + ckpt_path + \" does not exist.\")\n",
        "\n",
        "    checkpt = torch.load(ckpt_path)\n",
        "    if encoder is not None:\n",
        "        encoder_state = checkpt[\"encoder\"]\n",
        "        encoder.load_state_dict(encoder_state)\n",
        "        encoder.to(device)\n",
        "\n",
        "    if ode_func is not None:\n",
        "        ode_state = checkpt[\"ode\"]\n",
        "        ode_func.load_state_dict(ode_state)\n",
        "        ode_func.to(device)\n",
        "\n",
        "    if classifier is not None:\n",
        "        classifier_state = checkpt[\"classifier\"]\n",
        "        classifier.load_state_dict(classifier_state)\n",
        "        classifier.to(device)\n",
        "\n",
        "\n",
        "def get_logger(logpath, filepath, package_files=[], displaying=True, saving=True, debug=False):\n",
        "    logger = logging.getLogger()\n",
        "    if debug:\n",
        "        level = logging.DEBUG\n",
        "    else:\n",
        "        level = logging.INFO\n",
        "    logger.setLevel(level)\n",
        "    if saving:\n",
        "        info_file_handler = logging.FileHandler(logpath, mode=\"a\")\n",
        "        info_file_handler.setLevel(level)\n",
        "        logger.addHandler(info_file_handler)\n",
        "    if displaying:\n",
        "        console_handler = logging.StreamHandler()\n",
        "        console_handler.setLevel(level)\n",
        "        logger.addHandler(console_handler)\n",
        "    logger.info(filepath)\n",
        "    \"\"\"\n",
        "    with open(filepath, \"r\") as f:\n",
        "        logger.info(f.read())\n",
        "\n",
        "    for f in package_files:\n",
        "        logger.info(f)\n",
        "        with open(f, \"r\") as package_f:\n",
        "            logger.info(package_f.read())\n",
        "    \"\"\"\n",
        "\n",
        "    return logger\n",
        "\n",
        "\n",
        "def inf_generator(iterable):\n",
        "    \"\"\"Allows training with DataLoaders in a single infinite loop:\n",
        "        for i, (x, y) in enumerate(inf_generator(train_loader)):\n",
        "    \"\"\"\n",
        "    iterator = iterable.__iter__()\n",
        "    while True:\n",
        "        try:\n",
        "            yield iterator.__next__()\n",
        "        except StopIteration:\n",
        "            iterator = iterable.__iter__()\n",
        "\n",
        "\n",
        "def init_network_weights(net, std = 0.1):\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.normal_(m.weight, mean=0, std=std)\n",
        "            nn.init.constant_(m.bias, val=0)\n",
        "\n",
        "\n",
        "def reverse(tensor):\n",
        "    idx = [i for i in range(tensor.size(0)-1, -1, -1)]\n",
        "    return tensor[idx]\n",
        "\n",
        "\n",
        "def sample_standard_gaussian(mu, sigma):\n",
        "    device = get_device(mu)\n",
        "    d = torch.distributions.normal.Normal(\n",
        "            torch.Tensor([0.]).to(device),\n",
        "            torch.Tensor([1.]).to(device))\n",
        "    r = d.sample(mu.size()).squeeze(-1)\n",
        "    return r * sigma.float() + mu.float()\n",
        "\n",
        "\n",
        "def compute_loss_on_train(criterion, labels, preds):\n",
        "    preds = preds.permute(1, 0, 2)\n",
        "\n",
        "    idx_not_nan = ~(torch.isnan(labels).to(device) | (labels == -1))\n",
        "    # print(idx_not_nan)\n",
        "    preds = preds[idx_not_nan]\n",
        "    labels = labels[idx_not_nan]\n",
        "\n",
        "    return torch.sqrt(criterion(preds, labels)).to(device)\n",
        "\n",
        "\n",
        "def compute_loss_on_test(encoder, ode_func, classifier, dataloader, n_batches, device, phase):\n",
        "    ptnms = []\n",
        "    Times = torch.Tensor([]).to(device=device)\n",
        "    predictions = torch.Tensor([]).to(device=device)\n",
        "    ground_truth = torch.Tensor([]).to(device=device)\n",
        "    latent_dim = 6\n",
        "\n",
        "    for itr in range(n_batches):\n",
        "        ptnm, times, features, labels, cmax_time = dataloader.__next__()\n",
        "        dosing = torch.zeros([features.size(0), features.size(1), latent_dim]).to(device)\n",
        "        dosing[:, :, 0] = features[:, :, -2]\n",
        "        dosing = dosing.permute(1, 0, 2).to(device)\n",
        "\n",
        "        encoder_out = encoder(features)\n",
        "        qz0_mean, qz0_var = encoder_out[:, :latent_dim], encoder_out[:, latent_dim:]\n",
        "        z0 = sample_standard_gaussian(qz0_mean, qz0_var)\n",
        "\n",
        "        solves = z0.unsqueeze(0).clone()\n",
        "        try:\n",
        "            for idx, (time0, time1) in enumerate(zip(times[:-1], times[1:])):\n",
        "                z0 += dosing[idx]\n",
        "                time_interval = torch.Tensor([time0 - time0, time1 - time0]).to(device)\n",
        "                sol = odeint(ode_func, z0, time_interval, rtol=1e-4, atol=1e-4)\n",
        "                z0 = sol[-1].clone()\n",
        "                solves = torch.cat([solves, sol[-1:, :]], 0).to(device)\n",
        "        except AssertionError:\n",
        "            print(times)\n",
        "            print(time0, time1, time_interval, ptnm)\n",
        "            continue\n",
        "    \n",
        "        preds = classifier(solves, cmax_time).permute(1, 0, 2)\n",
        "\n",
        "\n",
        "        if phase == \"test\":\n",
        "            idx_not_nan = ~(torch.isnan(labels).to(device) | (labels == -1))\n",
        "            preds = preds[idx_not_nan]\n",
        "            labels = labels[idx_not_nan]\n",
        "\n",
        "\n",
        "            times = times[idx_not_nan.flatten()]\n",
        "            ptnms += ptnm * len(times)\n",
        "            Times = torch.cat((Times, times*24)).to(device)\n",
        "\n",
        "            predictions = torch.cat((predictions, preds)).to(device)\n",
        "            ground_truth = torch.cat((ground_truth, labels)).to(device)\n",
        "        \n",
        "        else:\n",
        "            \"\"\"\n",
        "            time_idx = (times >= 21)\n",
        "            preds = preds[:, time_idx, :]\n",
        "            labels = labels[:, time_idx, :]\n",
        "            \"\"\"\n",
        "            idx_not_nan = ~(torch.isnan(labels).to(device) | (labels == -1))\n",
        "            preds = preds[idx_not_nan]\n",
        "            labels = labels[idx_not_nan]\n",
        "\n",
        "            predictions = torch.cat((predictions, preds))\n",
        "            ground_truth = torch.cat((ground_truth, labels))\n",
        "\n",
        "    rmse_loss = mean_squared_error(\n",
        "        ground_truth.cpu().numpy(), predictions.cpu().numpy(),\n",
        "        squared=False\n",
        "    )\n",
        "    r2 = r2_score(ground_truth.cpu().numpy(), predictions.cpu().numpy())\n",
        "\n",
        "    if phase == \"test\":\n",
        "        return {\"PTNM\": ptnms,\n",
        "                \"TIME\": Times.cpu(),  \n",
        "                \"labels\": ground_truth.cpu().tolist(), \n",
        "                \"preds\": predictions.cpu().tolist(),\n",
        "                \"loss\": rmse_loss}\n",
        "    else:\n",
        "        return {\"labels\": ground_truth.cpu().tolist(), \n",
        "                \"preds\": predictions.cpu().tolist(),\n",
        "                \"loss\": rmse_loss,\n",
        "                \"r2\": r2}\n",
        "\n",
        "\n",
        "def compute_loss_on_interp(encoder, ode_func, classifier, dataloader, dataloader_o, n_batches, device, phase):\n",
        "    ptnms = []\n",
        "    Times = torch.Tensor([]).to(device=device)\n",
        "    predictions = torch.Tensor([]).to(device=device)\n",
        "    ground_truth = torch.Tensor([]).to(device=device)\n",
        "    latent_dim = 6\n",
        "\n",
        "    for itr in range(n_batches):\n",
        "        ptnm, times, features, labels, cmax_time = dataloader.__next__()\n",
        "        ptnm_o, times_o, features_o, labels_o, cmax_time_o = dataloader_o.__next__()\n",
        "        assert ptnm == ptnm_o\n",
        "\n",
        "        dosing = torch.zeros([features.size(0), features.size(1), latent_dim]).to(device)\n",
        "        dosing[:, :, 0] = features[:, :, -2]\n",
        "        dosing = dosing.permute(1, 0, 2)\n",
        "\n",
        "        encoder_out = encoder(features_o)\n",
        "        qz0_mean, qz0_var = encoder_out[:, :latent_dim], encoder_out[:, latent_dim:]\n",
        "        z0 = sample_standard_gaussian(qz0_mean, qz0_var)\n",
        "\n",
        "        solves = z0.unsqueeze(0).clone()\n",
        "        try:\n",
        "            for idx, (time0, time1) in enumerate(zip(times[:-1], times[1:])):\n",
        "                z0 += dosing[idx]\n",
        "                time_interval = torch.Tensor([time0 - time0, time1 - time0]).to(device)\n",
        "                sol = odeint(ode_func, z0, time_interval, rtol=1e-4, atol=1e-4)\n",
        "                z0 = sol[-1].clone()\n",
        "                solves = torch.cat([solves, sol[-1:, :]], 0).to(device)\n",
        "        except AssertionError:\n",
        "            print(times)\n",
        "            print(time0, time1, time_interval, ptnm)\n",
        "            continue\n",
        "    \n",
        "        preds = classifier(solves, cmax_time).permute(1, 0, 2)\n",
        "\n",
        "        idx_not_nan = ~(torch.isnan(labels).to(device) | (labels == -1))\n",
        "        print(idx_not_nan)\n",
        "        preds = preds[idx_not_nan]\n",
        "        labels = labels[idx_not_nan]\n",
        "\n",
        "        times = times[idx_not_nan.flatten()]\n",
        "        ptnms += ptnm * len(times)\n",
        "        Times = torch.cat((Times, times*24)).to(device)\n",
        "\n",
        "        predictions = torch.cat((predictions, preds)).to(device)\n",
        "        ground_truth = torch.cat((ground_truth, labels)).to(device)\n",
        "        \n",
        "    rmse_loss = mean_squared_error(\n",
        "        ground_truth.cpu().numpy(), predictions.cpu().numpy(),\n",
        "        squared=False\n",
        "    )\n",
        "    r2 = r2_score(ground_truth.cpu().numpy(), predictions.cpu().numpy())\n",
        "\n",
        "    return {\"PTNM\": ptnms,\n",
        "            \"TIME\": Times,  \n",
        "            \"labels\": ground_truth.cpu().tolist(), \n",
        "            \"preds\": predictions.cpu().tolist(),\n",
        "            \"loss\": rmse_loss}\n"
      ],
      "id": "28rTipF9DlsY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LD9ppyA2ZSL"
      },
      "source": [
        "# BRINGING IN THE ENTIRE MODEL.PY FILE"
      ],
      "id": "4LD9ppyA2ZSL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b45846cc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# from args import args\n",
        "# from torch.nn.modules.rnn import GRU, LSTM, RNN\n",
        "# import utils\n",
        "\n",
        "\n",
        "class ODEFunc(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, device=torch.device(\"cuda\")):\n",
        "        super(ODEFunc, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.SELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.SELU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.SELU(),\n",
        "            nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "\n",
        "        for m in self.net.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.001)\n",
        "                nn.init.constant_(m.bias, val=0.5)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        # print(x)\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, device=torch.device(\"cuda\")):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.device = device\n",
        "\n",
        "        self.hiddens_to_output = nn.Sequential(\n",
        "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_dim, self.output_dim),\n",
        "        )\n",
        "        init_network_weights(self.hiddens_to_output, std=0.001)\n",
        "\n",
        "        # self.rnn = nn.RNN(self.input_dim, self.hidden_dim, nonlinearity=\"relu\").to(device)\n",
        "        self.rnn = nn.GRU(self.input_dim, self.hidden_dim).to(device)\n",
        "\n",
        "    def forward(self, data):\n",
        "        data = data.permute(1, 0, 2)\n",
        "        data = reverse(data)\n",
        "        output_rnn, _ = self.rnn(data)\n",
        "        #print(output_rnn)\n",
        "        outputs = self.hiddens_to_output(output_rnn[-1])\n",
        "        #print(outputs)\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim, output_dim, device=torch.device(\"cuda\")):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(latent_dim + 20, 32),\n",
        "            nn.SELU(),\n",
        "            nn.Linear(32, output_dim),\n",
        "        )\n",
        "        \n",
        "        init_network_weights(self.net, std=0.001)\n",
        "\n",
        "    def forward(self, z, cmax_time):\n",
        "        cmax_time = cmax_time.repeat(z.size(0), 1, 1)\n",
        "        z = torch.cat([z, cmax_time], 2)\n",
        "        return self.net(z)\n"
      ],
      "id": "b45846cc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg3Lv2AK2WT9"
      },
      "source": [
        "# BRINGING IN THE ENTIRE EVALUATION.PY FILE"
      ],
      "id": "Bg3Lv2AK2WT9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c726db29"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "\n",
        "def score(df, label_col, pred_col, score_fn):\n",
        "    y_true = df[label_col].values\n",
        "    y_pred = df[pred_col].values\n",
        "    if score_fn is mean_squared_error:\n",
        "        return score_fn(y_true, y_pred, squared=False)\n",
        "    elif score_fn is pearsonr:\n",
        "        return score_fn(y_true, y_pred)[0]\n",
        "    else:\n",
        "        return score_fn(y_true, y_pred)\n",
        "    \n",
        "\n",
        "def merge_predictions(files, method=\"mean\"):\n",
        "    cols = ['PTNM','TIME','preds']\n",
        "    left = pd.read_csv(files[0])\n",
        "    for f in files[1:]:\n",
        "        right = pd.read_csv(f)\n",
        "        left = left.merge(right[cols], on=[\"PTNM\", \"TIME\"], how=\"left\")\n",
        "    preds = [col for col in left.columns.values if col.startswith(\"preds\")]\n",
        "    left[\"pred_agg\"] = left[preds].agg(method, axis=1)\n",
        "    left = left[left.TIME >= 168]\n",
        "    print(left.shape)\n",
        "    return left\n",
        "\n",
        "def write_score(pred_df, fold, model_name, rmse_dict, score_fn):\n",
        "    res = score(pred_df, \"labels\", \"pred_agg\", score_fn)\n",
        "    if not rmse_dict.get(\"fold\", []) or rmse_dict[\"fold\"][-1] != fold:\n",
        "        rmse_dict[\"fold\"] = rmse_dict.get(\"fold\", []) + [fold]\n",
        "    rmse_dict[model_name] = rmse_dict.get(model_name, []) + [round(res, 5)]\n",
        "\n",
        "\n",
        "def main(score_type, score_fn, folds, models):\n",
        "    records = {}\n",
        "    for fold in folds:\n",
        "        in_file = [\"fold_{}/fold_{}_model_{}.csv\".format(fold, fold, m) for m in models]\n",
        "        predictions = merge_predictions(in_file)\n",
        "        predictions.to_csv(\"predictions.csv\", index=False)\n",
        "        write_score(predictions, fold, \"ensemble (mean)\", records, score_fn)\n",
        "\n",
        "        for f in in_file:\n",
        "            predictions = merge_predictions([f])\n",
        "            write_score(predictions, fold, f.split(\"/\")[1], records, score_fn)\n",
        "    \n",
        "    df = pd.DataFrame(records)\n",
        "    print(df)\n",
        "    summary_df = df.drop(columns=\"fold\").agg([\"min\", \"max\", \"mean\", \"median\"])\n",
        "    print(summary_df)\n",
        "    df.to_csv(f\"{score_type}.txt\", sep=\"\\t\", index=False)\n",
        "    summary_df.to_csv(f\"{score_type}_summary.txt\", sep=\"\\t\", index=False)\n",
        "\n",
        "\n",
        "  # main(\"rmse\", mean_squared_error, args)\n",
        "  # main(\"r2\", r2_score, args)\n",
        "  # main(\"correlation\", pearsonr, args)\n"
      ],
      "id": "c726db29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3wcV85y2TEy"
      },
      "source": [
        "# BRINGING IN THE ENTIRE DATA_PARSE.PY FILE"
      ],
      "id": "F3wcV85y2TEy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf7PsFHjEaMU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class TDM1(Dataset):\n",
        "\n",
        "    def __init__(self, data_to_load, label_col, feature_cols, device, phase=\"train\"):\n",
        "        self.data = pd.read_csv(data_to_load)\n",
        "\n",
        "        self.label_col = label_col\n",
        "        self.features = feature_cols\n",
        "        self.device = device\n",
        "        self.phase = phase\n",
        "        self.data[\"TIME\"] = self.data[\"TIME\"] / 24\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.PTNM.unique().shape[0] \n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        ptnm = self.data.PTNM.unique()[index]\n",
        "        cur_data = self.data[self.data[\"PTNM\"] == ptnm]\n",
        "        times, features, labels, cmax_time = self.process(cur_data)\n",
        "        return ptnm, times, features, labels, cmax_time\n",
        "\n",
        "    def process(self, data):\n",
        "        data = data.reset_index(drop=True)\n",
        "        \"\"\"\n",
        "        if self.phase == \"train\":\n",
        "            random_time = np.random.randint(low=21, high=int(data[\"TIME\"].max()) + 1)\n",
        "            data = data[data.TIME <= random_time]\n",
        "        else:\n",
        "            pass\n",
        "        \"\"\"\n",
        "        if (data.DSFQ == 1).all():\n",
        "            cmax_time = data.loc[data.TIME < 7, [\"TIME\", \"PK_timeCourse\"]].values.flatten()\n",
        "            cmax = data.loc[data.TIME < 7, \"PK_timeCourse\"].max()\n",
        "        else:\n",
        "            cmax_time = data.loc[data.TIME < 21, [\"TIME\", \"PK_timeCourse\"]].values.flatten()\n",
        "            cmax = data.loc[data.TIME < 21, \"PK_timeCourse\"].max()\n",
        "\n",
        "        cmax_time_full = np.zeros((20, ))\n",
        "        if len(cmax_time) <= 20:\n",
        "            cmax_time_full[:len(cmax_time)] = cmax_time\n",
        "        else:\n",
        "            cmax_time_full[:] = cmax_time[:20]\n",
        "        \n",
        "        data[\"PK_round1\"] = data[\"PK_round1\"] / cmax\n",
        "\n",
        "        features = data[self.features].values\n",
        "        labels = data[self.label_col].values\n",
        "        times = data[\"TIME\"].values\n",
        "\n",
        "        times = torch.from_numpy(times)\n",
        "        features = torch.from_numpy(features)\n",
        "        labels = torch.from_numpy(labels).unsqueeze_(-1)\n",
        "        cmax_time_full = torch.from_numpy(cmax_time_full)\n",
        "        return times, features, labels, cmax_time_full\n",
        "\n",
        "\n",
        "def tdm1_collate_fn(batch, device=device):\n",
        "    D = batch[0][2].shape[1]\n",
        "    N = 1\n",
        "\n",
        "    combined_tt, inverse_indices = torch.unique(torch.cat([ex[1] for ex in batch]),\n",
        "        sorted=True, return_inverse=True)\n",
        "    combined_tt = combined_tt.to(device)\n",
        "    # print(combined_tt, inverse_indices)\n",
        "\n",
        "    offset = 0\n",
        "    combined_features = torch.zeros([len(batch), len(combined_tt), D]).to(device)\n",
        "    combined_label = torch.zeros([len(batch), len(combined_tt), N]).to(device)\n",
        "    combined_label[:] = np.nan\n",
        "    combined_cmax_time = torch.zeros([len(batch), 20]).to(device)\n",
        "    # print(combined_label.shape)\n",
        "\n",
        "    ptnms = []\n",
        "    for b, (ptnm, tt, features, label, cmax_time) in enumerate(batch):\n",
        "        ptnms.append(ptnm)\n",
        "        tt = tt.to(device)\n",
        "        features = features.to(device)\n",
        "        label = label.to(device)\n",
        "        cmax_time = cmax_time.to(device)\n",
        "\n",
        "        indices = inverse_indices[offset:offset + len(tt)]\n",
        "        offset += len(tt)\n",
        "\n",
        "        combined_features[b, indices] = features.float()\n",
        "        combined_label[b, indices] = label.float()\n",
        "        combined_cmax_time[b, :] = cmax_time.float()\n",
        "    combined_tt = combined_tt.float()\n",
        "\n",
        "    return ptnms, combined_tt, combined_features, combined_label, combined_cmax_time\n",
        "\n",
        "\n",
        "def parse_tdm1(device, phase=\"train\"):\n",
        "    train_data_path = \"train.csv\"\n",
        "    val_data_path = \"validate.csv\"\n",
        "    test_data_path = \"test.csv\"\n",
        "\n",
        "    feature_cols = ['TFDS','TIME','CYCL','AMT',\"PK_round1\"]\n",
        "    \"\"\"\n",
        "    covariates = ['SEX','AGE','WT','RACR','RACE','BSA',\n",
        "                  'BMI','ALBU','TPRO','WBC','CRCL','CRET',\n",
        "                  'SGOT','SGPT','TBIL','TMBD','ALKP', 'HER', \n",
        "                  'ECOG','KEOALL','ASIAN']\n",
        "    feature_cols += covariates\n",
        "    \"\"\"\n",
        "    label_col = \"PK_timeCourse\"\n",
        "    train = TDM1(train_data_path, label_col, feature_cols, device, phase=\"train\")\n",
        "    validate = TDM1(val_data_path, label_col, feature_cols, device, phase=\"validate\")\n",
        "    test = TDM1(test_data_path, label_col, feature_cols, device, phase=\"test\")\n",
        "\n",
        "    ptnm, times, features, labels, cmax_time = train[0]\n",
        "    input_dim = features.size(-1)\n",
        "    # n_labels = 1\n",
        "\n",
        "    if phase == \"train\":\n",
        "        train_dataloader = DataLoader(train, batch_size=1, shuffle=True, \n",
        "            collate_fn=lambda batch: tdm1_collate_fn(batch, device))\n",
        "        val_dataloader = DataLoader(validate, batch_size=1, shuffle=False,\n",
        "            collate_fn=lambda batch: tdm1_collate_fn(batch, device))\n",
        "\n",
        "        dataset_objs = {\n",
        "            \"train_dataloader\": inf_generator(train_dataloader),\n",
        "            \"val_dataloader\": inf_generator(val_dataloader),\n",
        "            \"n_train_batches\": len(train_dataloader),\n",
        "            \"n_val_batches\": len(val_dataloader),\n",
        "            \"input_dim\": input_dim\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        test_dataloader = DataLoader(test, batch_size=1, shuffle=False,\n",
        "            collate_fn=lambda batch: tdm1_collate_fn(batch, device))\n",
        "\n",
        "        dataset_objs = {\n",
        "            \"test_dataloader\": inf_generator(test_dataloader),\n",
        "            \"n_test_batches\": len(test_dataloader),\n",
        "            \"input_dim\": input_dim\n",
        "        }\n",
        "\n",
        "    return dataset_objs\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"run\")\n",
        "#     data = parse_tdm1(\"cpu\")\n",
        "#     for ptnms, times, features, labels, cmax_time in data[\"train_dataloader\"]:\n",
        "#         print(ptnms)\n",
        "#         print(times)\n",
        "#         print(features)\n",
        "#         print(labels)\n",
        "#         print(cmax_time)\n",
        "#         break\n"
      ],
      "id": "mf7PsFHjEaMU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXiXw8uu2OUB"
      },
      "source": [
        "# BRINGING IN THE ENTIRE RUNTRAIN.PY FILE"
      ],
      "id": "QXiXw8uu2OUB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceqyaeP5D-qu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import SystemRandom\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchdiffeq import odeint_adjoint as odeint\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# import utils\n",
        "# from model import *\n",
        "# from data_parse import parse_tdm1\n",
        "# from args import args\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "file_name = os.path.basename(\"__file__\")[:-3]\n",
        "\n",
        "\n",
        "input_cmd = sys.argv\n",
        "input_cmd = \" \".join(input_cmd)\n",
        "\n",
        "########################################################################\n",
        "## Main runnings\n",
        "def runtraining(random_seed, model, fold, lr=0.00005, l2=0.1, epochs=30, tol=1e-4, continue_train=False):\n",
        "  save = f\"Fold{fold}\"\n",
        "  makedirs(save)\n",
        "  torch.manual_seed(random_seed + model + fold)\n",
        "  np.random.seed(random_seed + model + fold)\n",
        "\n",
        "  ckpt_path = os.path.join(save, f\"fold_{fold}_model_{model}.ckpt\")\n",
        "  ########################################################################\n",
        "  tdm1_obj = parse_tdm1(device, phase=\"train\")\n",
        "  input_dim = tdm1_obj[\"input_dim\"]\n",
        "  hidden_dim = 128\n",
        "  latent_dim = 6\n",
        "\n",
        "  encoder = Encoder(input_dim=input_dim, output_dim=2 * latent_dim, hidden_dim=hidden_dim).to(device)\n",
        "  ode_func = ODEFunc(input_dim=latent_dim, hidden_dim=16).to(device)\n",
        "  classifier = Classifier(latent_dim=latent_dim, output_dim=1).to(device)\n",
        "\n",
        "  # torch.save({'encoder': encoder.state_dict(), 'ode': ode_func.state_dict(), 'classifier': classifier.state_dict()}, ckpt_path)\n",
        "\n",
        "  if continue_train:\n",
        "      load_model(ckpt_path, encoder, ode_func, classifier, device)\n",
        "\n",
        "  ########################################################################\n",
        "  ## Train\n",
        "  log_path = \"logs/\" + f\"fold_{fold}_model_{model}.log\"\n",
        "  makedirs(\"logs/\")\n",
        "  logger = get_logger(logpath=log_path, filepath=os.path.abspath(\"__file__\"))\n",
        "  logger.info(input_cmd)\n",
        "\n",
        "  batches_per_epoch = tdm1_obj[\"n_train_batches\"]\n",
        "  criterion = nn.MSELoss().to(device=device)\n",
        "  params = (list(encoder.parameters()) + \n",
        "            list(ode_func.parameters()) + \n",
        "            list(classifier.parameters()))\n",
        "  optimizer = optim.Adam(params, lr=lr, weight_decay=l2)\n",
        "  best_rmse = 0x7fffffff\n",
        "  best_epochs = 0\n",
        "\n",
        "  for epoch in range(1, epochs):\n",
        "\n",
        "      for _ in tqdm(range(batches_per_epoch), ascii=True):\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          ptnms, times, features, labels, cmax_time = tdm1_obj[\"train_dataloader\"].__next__()\n",
        "          dosing = torch.zeros([features.size(0), features.size(1), latent_dim]).to(device)\n",
        "          dosing[:, :, 0] = features[:, :, -2]\n",
        "          dosing = dosing.permute(1, 0, 2)\n",
        "\n",
        "          encoder_out = encoder(features)\n",
        "          qz0_mean, qz0_var = encoder_out[:, :latent_dim], encoder_out[:, latent_dim:]\n",
        "          z0 = sample_standard_gaussian(qz0_mean, qz0_var).to(device)\n",
        "          \n",
        "          solves = z0.unsqueeze(0).clone()\n",
        "          try:\n",
        "              for idx, (time0, time1) in enumerate(zip(times[:-1], times[1:])):\n",
        "                  z0 += dosing[idx]\n",
        "                  # print(z0.device)\n",
        "                  time_interval = torch.Tensor([time0 - time0, time1 - time0]).to(device)\n",
        "                  sol = odeint(ode_func, z0, time_interval, rtol=tol, atol=tol).to(device)\n",
        "                  z0 = sol[-1].clone()\n",
        "                  solves = torch.cat([solves, sol[-1:, :]], 0).to(device)\n",
        "          except AssertionError:\n",
        "              print(times)\n",
        "              print(time0, time1, time_interval, ptnms)\n",
        "              continue\n",
        "      \n",
        "          preds = classifier(solves, cmax_time)\n",
        "\n",
        "          loss = compute_loss_on_train(criterion, labels, preds)\n",
        "          try: \n",
        "              loss.backward()\n",
        "          except RuntimeError:\n",
        "              print(ptnms)\n",
        "              print(times)\n",
        "              continue\n",
        "          optimizer.step()\n",
        "      \n",
        "      idx_not_nan = ~(torch.isnan(labels) | (labels == -1))\n",
        "      preds = preds.permute(1, 0, 2)[idx_not_nan]\n",
        "      labels = labels[idx_not_nan]\n",
        "      print(preds)\n",
        "      print(labels)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          \n",
        "          train_res = compute_loss_on_test(encoder, ode_func, classifier,\n",
        "              tdm1_obj[\"train_dataloader\"], tdm1_obj[\"n_train_batches\"], \n",
        "              device, phase=\"train\")\n",
        "\n",
        "          validation_res = compute_loss_on_test(encoder, ode_func, classifier,\n",
        "              tdm1_obj[\"val_dataloader\"], tdm1_obj[\"n_val_batches\"], \n",
        "              device, phase=\"validate\")\n",
        "          \n",
        "          train_loss = train_res[\"loss\"] \n",
        "          validation_loss = validation_res[\"loss\"]\n",
        "          if validation_loss < best_rmse:\n",
        "              torch.save({'encoder': encoder.state_dict(),\n",
        "                          'ode': ode_func.state_dict(),\n",
        "                          'classifier': classifier.state_dict()}, ckpt_path)\n",
        "              best_rmse = validation_loss\n",
        "              best_epochs = epoch\n",
        "\n",
        "          message = \"\"\"\n",
        "          Epoch {:04d} | Training loss {:.6f} | Training R2 {:.6f} | Validation loss {:.6f} | Validation R2 {:.6f}\n",
        "          Best loss {:.6f} | Best epoch {:04d}\n",
        "          \"\"\".format(epoch, train_loss, train_res[\"r2\"], validation_loss, validation_res[\"r2\"], best_rmse, best_epochs)\n",
        "          logger.info(message)\n",
        "            "
      ],
      "id": "ceqyaeP5D-qu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF0BbIABZwSK"
      },
      "source": [
        "#BRINGING IN THE ENTIRE RUNPREDICT.PY FILE"
      ],
      "id": "eF0BbIABZwSK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6Ec90W8Arpv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "###############################################################\n",
        "## Main runnings\n",
        "def runpredict(random_seed, model, fold, lr=0.00005, l2=0.1, epochs=30, tol=1e-4, continue_train=True):\n",
        "  save = f\"Fold{fold}\"\n",
        "  makedirs(save)\n",
        "  ckpt_path = os.path.join(save, f\"fold_{fold}_model_{model}.ckpt\")\n",
        "  eval_path = os.path.join(save, f\"fold_{fold}_model_{model}.csv\")\n",
        "  res_path = \"rmse.csv\"\n",
        "\n",
        "  ########################################################################\n",
        "  tdm1_obj = parse_tdm1(device, phase=\"test\")\n",
        "  input_dim = tdm1_obj[\"input_dim\"]\n",
        "  hidden_dim = 128 \n",
        "  latent_dim = 6\n",
        "\n",
        "  encoder = Encoder(input_dim=input_dim, output_dim=2 * latent_dim, hidden_dim=hidden_dim)\n",
        "  ode_func = ODEFunc(input_dim=latent_dim, hidden_dim=16)\n",
        "  classifier = Classifier(latent_dim=latent_dim, output_dim=1)\n",
        "\n",
        "  load_model(ckpt_path, encoder, ode_func, classifier, device)\n",
        "\n",
        "  ########################################################################\n",
        "  ## Predict & Evaluate\n",
        "  with torch.no_grad():\n",
        "      test_res = compute_loss_on_test(encoder, ode_func, classifier,\n",
        "          tdm1_obj[\"test_dataloader\"], tdm1_obj[\"n_test_batches\"], \n",
        "          device, phase=\"test\")\n",
        "      \n",
        "\n",
        "  eval_results = pd.DataFrame(test_res).drop(columns=\"loss\")\n",
        "  eval_results.to_csv(eval_path, index=False)\n",
        "\n",
        "  \"\"\"\n",
        "  with torch.no_grad():\n",
        "      test_res = utils.compute_loss_on_interp(encoder, ode_func, classifier, args,\n",
        "          tdm1_obj[\"interp_dataloader\"], tdm1_obj[\"test_dataloader\"], tdm1_obj[\"n_interp_batches\"], \n",
        "          device, phase=\"test\")\n",
        "\n",
        "  eval_results = pd.DataFrame(test_res).drop(columns=\"loss\")\n",
        "  eval_results.to_csv(eval_path + \".interp\", index=False)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      test_res = utils.compute_loss_on_interp(encoder, ode_func, classifier, args,\n",
        "          tdm1_obj[\"nodosing_dataloader\"], tdm1_obj[\"test_dataloader\"], tdm1_obj[\"n_interp_batches\"], \n",
        "          device, phase=\"test\")\n",
        "\n",
        "  eval_results = pd.DataFrame(test_res).drop(columns=\"loss\")\n",
        "  eval_results.to_csv(eval_path + \".nodosing\", index=False)\n",
        "  \"\"\""
      ],
      "id": "D6Ec90W8Arpv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQgnLCvfZ5LD"
      },
      "source": [
        "RUNNING THE NEURAL-ODE MODEL"
      ],
      "id": "CQgnLCvfZ5LD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn8tiB7Z9s2-",
        "outputId": "ea1be90d-b444-48ed-c1db-6e09dfea84b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a1547cc7bd9e>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"PTNM\"] = df[\"PTNM\"] + str(0.1)\n",
            "<ipython-input-13-a1547cc7bd9e>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"PTNM\"] = df[\"PTNM\"] + str(0.2)\n",
            "<ipython-input-13-a1547cc7bd9e>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"PTNM\"] = df[\"PTNM\"] + str(0.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5010\n",
            "5011\n",
            "5012\n",
            "5013\n",
            "5014\n",
            "5015\n",
            "5016\n",
            "5209\n",
            "5210\n",
            "5211\n",
            "5212\n",
            "5409\n",
            "5410\n",
            "5411\n",
            "5412\n",
            "5413\n",
            "5414\n",
            "5415\n",
            "5416\n",
            "5602\n",
            "5603\n",
            "5604\n",
            "5605\n",
            "5606\n",
            "5607\n",
            "5608\n",
            "5609\n",
            "5610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:/content/__file__\n",
            "/content/__file__\n",
            "INFO:root:/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-395d1998-8e4e-4dc9-a7fa-cdd8edebe74a.json\n",
            "/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-395d1998-8e4e-4dc9-a7fa-cdd8edebe74a.json\n",
            "100%|##########| 672/672 [04:43<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.2391,  5.1717,  8.8703,  9.2620, 12.9289, 13.1532, 13.3494, 17.0739,\n",
            "        17.2425], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 5.8156,  0.8816, 16.1310,  0.8871, 19.8420,  3.7824,  0.8870, 20.1590,\n",
            "         5.8156], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0001 | Training loss 26.341450 | Training R2 -0.768458 | Validation loss 28.023655 | Validation R2 -1.255971\n",
            "          Best loss 28.023655 | Best epoch 0001\n",
            "          \n",
            "\n",
            "          Epoch 0001 | Training loss 26.341450 | Training R2 -0.768458 | Validation loss 28.023655 | Validation R2 -1.255971\n",
            "          Best loss 28.023655 | Best epoch 0001\n",
            "          \n",
            "100%|##########| 672/672 [04:40<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9732, 4.5797, 4.7871, 7.2709, 7.4598], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor([0.1803, 6.8826, 0.1879, 5.1060, 0.1803], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0002 | Training loss 27.136173 | Training R2 -0.876777 | Validation loss 29.782393 | Validation R2 -1.548022\n",
            "          Best loss 28.023655 | Best epoch 0001\n",
            "          \n",
            "\n",
            "          Epoch 0002 | Training loss 27.136173 | Training R2 -0.876777 | Validation loss 29.782393 | Validation R2 -1.548022\n",
            "          Best loss 28.023655 | Best epoch 0001\n",
            "          \n",
            "100%|##########| 672/672 [04:38<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3512, 2.2844, 2.2852, 2.2861, 2.2869, 2.2901, 2.2925, 2.2958, 2.2982,\n",
            "        2.3006, 3.0193, 3.0262, 3.0282, 3.0332, 3.0391, 3.6152, 3.6231, 3.6309,\n",
            "        3.6376], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([0.1027, 4.3675, 3.3207, 2.6789, 2.2198, 1.1160, 0.6726, 0.3426, 0.2066,\n",
            "        0.1245, 4.4427, 1.1442, 0.8164, 0.3513, 0.1277, 4.4458, 1.1451, 0.3516,\n",
            "        0.1278], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0003 | Training loss 26.767849 | Training R2 -0.826175 | Validation loss 29.269934 | Validation R2 -1.461090\n",
            "          Best loss 28.023655 | Best epoch 0001\n",
            "          \n",
            "\n",
            "          Epoch 0003 | Training loss 26.767849 | Training R2 -0.826175 | Validation loss 29.269934 | Validation R2 -1.461090\n",
            "          Best loss 28.023655 | Best epoch 0001\n",
            "          \n",
            "100%|##########| 672/672 [04:37<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4.1092,  9.2334,  9.0717,  8.9328, 13.0813, 12.9160, 12.7743],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 1.3031, 17.1530,  4.2189,  1.2679, 17.6280,  4.3359,  1.3031],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0004 | Training loss 24.577896 | Training R2 -0.539589 | Validation loss 25.545418 | Validation R2 -0.874606\n",
            "          Best loss 25.545418 | Best epoch 0004\n",
            "          \n",
            "\n",
            "          Epoch 0004 | Training loss 24.577896 | Training R2 -0.539589 | Validation loss 25.545418 | Validation R2 -0.874606\n",
            "          Best loss 25.545418 | Best epoch 0004\n",
            "          \n",
            "100%|##########| 672/672 [04:39<00:00,  2.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([13.4741, 18.5694, 17.9659, 16.8139, 21.7352, 20.9481, 19.4488],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([17.6690, 69.9310, 19.6240,  2.0229, 70.4890, 19.8330,  2.0444],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0005 | Training loss 18.737062 | Training R2 0.105216 | Validation loss 17.964836 | Validation R2 0.072892\n",
            "          Best loss 17.964836 | Best epoch 0005\n",
            "          \n",
            "\n",
            "          Epoch 0005 | Training loss 18.737062 | Training R2 0.105216 | Validation loss 17.964836 | Validation R2 0.072892\n",
            "          Best loss 17.964836 | Best epoch 0005\n",
            "          \n",
            "100%|##########| 672/672 [04:37<00:00,  2.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10.7882, 18.6375], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 7.8802, 54.9540], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0006 | Training loss 18.679979 | Training R2 0.110659 | Validation loss 17.838053 | Validation R2 0.085931\n",
            "          Best loss 17.838053 | Best epoch 0006\n",
            "          \n",
            "\n",
            "          Epoch 0006 | Training loss 18.679979 | Training R2 0.110659 | Validation loss 17.838053 | Validation R2 0.085931\n",
            "          Best loss 17.838053 | Best epoch 0006\n",
            "          \n",
            "100%|##########| 672/672 [04:40<00:00,  2.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 3.4977, 10.9911,  9.3939,  7.9964, 13.2339,  7.3523, 12.4247,  5.2493,\n",
            "        10.0115,  3.1056], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 2.5158, 10.0050,  2.5792,  0.8070, 40.4740,  0.8047, 40.4720,  0.8047,\n",
            "        39.6060,  0.7875], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0007 | Training loss 18.294975 | Training R2 0.146941 | Validation loss 17.784164 | Validation R2 0.091446\n",
            "          Best loss 17.784164 | Best epoch 0007\n",
            "          \n",
            "\n",
            "          Epoch 0007 | Training loss 18.294975 | Training R2 0.146941 | Validation loss 17.784164 | Validation R2 0.091446\n",
            "          Best loss 17.784164 | Best epoch 0007\n",
            "          \n",
            "100%|##########| 672/672 [04:45<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5.0489,  9.5644,  9.1430, 15.3729,  8.7122,  7.6244, 13.7716,  5.7963,\n",
            "         5.1712,  4.2042,  3.8961,  5.3573,  3.0964,  4.1691,  3.0957],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 8.4665,  2.6608,  2.2691, 18.5760,  3.2225,  2.3435, 25.5770,  3.2261,\n",
            "         2.3462,  3.2262,  2.3463, 25.6730,  2.3549, 30.2890,  8.4665],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0008 | Training loss 18.257090 | Training R2 0.150470 | Validation loss 17.998465 | Validation R2 0.069417\n",
            "          Best loss 17.784164 | Best epoch 0007\n",
            "          \n",
            "\n",
            "          Epoch 0008 | Training loss 18.257090 | Training R2 0.150470 | Validation loss 17.998465 | Validation R2 0.069417\n",
            "          Best loss 17.784164 | Best epoch 0007\n",
            "          \n",
            "100%|##########| 672/672 [04:42<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([19.9414, 45.5474], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([19.2920, 85.6310], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0009 | Training loss 16.834253 | Training R2 0.277724 | Validation loss 17.300528 | Validation R2 0.140190\n",
            "          Best loss 17.300528 | Best epoch 0009\n",
            "          \n",
            "\n",
            "          Epoch 0009 | Training loss 16.834253 | Training R2 0.277724 | Validation loss 17.300528 | Validation R2 0.140190\n",
            "          Best loss 17.300528 | Best epoch 0009\n",
            "          \n",
            "100%|##########| 672/672 [04:41<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8.6609, 27.2044, 22.9676, 18.6471, 14.8763,  8.7254, 13.0352,  8.5347,\n",
            "         6.6915,  8.4333,  7.3392,  6.6012,  6.5200,  7.8282,  7.1562,  6.4779,\n",
            "         6.3803,  7.5840,  6.7952,  5.9959,  5.8809,  7.0077,  6.0941,  5.1688,\n",
            "         5.0257,  6.0533,  5.2046,  4.7167,  5.3301,  4.8579,  4.3112,  4.8474,\n",
            "         4.3210,  3.7116,  4.2703,  3.7692], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor([ 7.2829, 42.8440, 12.3400,  4.1313,  1.6174,  1.6724, 20.9970,  5.9940,\n",
            "         1.7166, 17.7690,  5.9424,  1.9898,  1.7019, 17.6790,  5.9126,  1.9798,\n",
            "         1.6933, 17.6670,  5.9084,  1.9784,  1.6921, 17.9310,  5.9966,  2.0079,\n",
            "         1.7174, 17.9400,  5.9999,  1.7183, 17.9410,  6.0000,  1.7184, 17.4120,\n",
            "         5.8233,  1.6677, 18.6260,  7.2829], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0010 | Training loss 16.071266 | Training R2 0.341713 | Validation loss 16.373804 | Validation R2 0.229836\n",
            "          Best loss 16.373804 | Best epoch 0010\n",
            "          \n",
            "\n",
            "          Epoch 0010 | Training loss 16.071266 | Training R2 0.341713 | Validation loss 16.373804 | Validation R2 0.229836\n",
            "          Best loss 16.373804 | Best epoch 0010\n",
            "          \n",
            "100%|##########| 672/672 [04:42<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([17.9965, 27.2236, 26.5087, 25.7919], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor([31.1600, 21.5030, 17.4770, 14.5830], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0011 | Training loss 15.341714 | Training R2 0.400122 | Validation loss 15.422334 | Validation R2 0.316743\n",
            "          Best loss 15.422334 | Best epoch 0011\n",
            "          \n",
            "\n",
            "          Epoch 0011 | Training loss 15.341714 | Training R2 0.400122 | Validation loss 15.422334 | Validation R2 0.316743\n",
            "          Best loss 15.422334 | Best epoch 0011\n",
            "          \n",
            "100%|##########| 672/672 [04:41<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([14.3396, 44.7900, 43.5865, 42.3810, 41.1735, 37.5388, 56.6964, 52.9522,\n",
            "        45.4368, 63.3831, 55.7440, 48.0819, 45.2357, 57.9942, 41.0654, 50.5978,\n",
            "        37.1669, 42.2982, 34.6367, 39.4978, 33.3567, 37.6751, 31.0308, 34.0545,\n",
            "        31.2226, 33.9361, 31.2001, 33.7443, 31.7898], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor([20.7140, 46.6930, 36.3750, 29.6610, 24.7630, 15.1220, 59.5840, 39.0430,\n",
            "        20.0970, 63.5550, 35.3180, 21.6870, 21.4910, 52.0110, 22.1980, 50.6250,\n",
            "        21.6590, 41.1430, 21.2610, 42.8590, 22.1220, 43.3930, 22.4050, 41.0620,\n",
            "        21.2290, 40.3330, 20.8420, 40.0930, 20.7140], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0012 | Training loss 14.818567 | Training R2 0.440335 | Validation loss 14.742236 | Validation R2 0.375675\n",
            "          Best loss 14.742236 | Best epoch 0012\n",
            "          \n",
            "\n",
            "          Epoch 0012 | Training loss 14.818567 | Training R2 0.440335 | Validation loss 14.742236 | Validation R2 0.375675\n",
            "          Best loss 14.742236 | Best epoch 0012\n",
            "          \n",
            "100%|##########| 672/672 [04:42<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 9.0743, 30.1433, 10.3643, 30.3810, 17.6184,  9.6584, 17.0900, 14.0828,\n",
            "        10.7773, 14.1977, 11.7057, 14.7096, 11.8826, 11.6649, 14.4221, 11.7998,\n",
            "        13.6988, 12.6351, 12.5533, 14.3729, 13.0718, 14.8133, 13.4604, 13.3564,\n",
            "        13.3852, 14.9641, 13.1994, 12.7226, 14.1258, 13.0930, 12.0605, 13.4694,\n",
            "        12.3585], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 9.4905, 23.3070,  3.3688, 62.3120, 21.5050,  3.5695, 43.4420, 24.6750,\n",
            "         3.5667, 25.0220,  3.6169, 24.3010,  4.0329,  3.5126, 24.4200,  3.5299,\n",
            "        24.5050,  4.0669,  3.5422, 24.5080,  3.5425, 24.5080,  4.0673,  3.5426,\n",
            "         3.5090, 24.4200,  3.5298,  3.4397, 24.1540,  9.1820,  3.4914, 24.9650,\n",
            "         9.4905], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0013 | Training loss 14.444537 | Training R2 0.468231 | Validation loss 14.422903 | Validation R2 0.402429\n",
            "          Best loss 14.422903 | Best epoch 0013\n",
            "          \n",
            "\n",
            "          Epoch 0013 | Training loss 14.444537 | Training R2 0.468231 | Validation loss 14.422903 | Validation R2 0.402429\n",
            "          Best loss 14.422903 | Best epoch 0013\n",
            "          \n",
            "100%|##########| 672/672 [04:41<00:00,  2.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2.9864, 23.8703,  7.7314, 22.6760, 14.1833,  8.5523, 15.4518, 12.8690,\n",
            "        10.6400,  9.7570], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 0.9887, 13.2440,  1.0495, 44.2920, 11.1530,  1.0742, 43.9160, 13.4380,\n",
            "         2.8234,  1.0649], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0014 | Training loss 14.236508 | Training R2 0.483438 | Validation loss 14.391095 | Validation R2 0.405062\n",
            "          Best loss 14.391095 | Best epoch 0014\n",
            "          \n",
            "\n",
            "          Epoch 0014 | Training loss 14.236508 | Training R2 0.483438 | Validation loss 14.391095 | Validation R2 0.405062\n",
            "          Best loss 14.391095 | Best epoch 0014\n",
            "          \n",
            "100%|##########| 672/672 [04:42<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([12.9101, 55.2716, 25.1442, 11.1457, 22.6034], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor([16.1690, 59.8340,  5.3050,  1.4892, 16.1690], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0015 | Training loss 13.887590 | Training R2 0.508448 | Validation loss 13.889879 | Validation R2 0.445782\n",
            "          Best loss 13.889879 | Best epoch 0015\n",
            "          \n",
            "\n",
            "          Epoch 0015 | Training loss 13.887590 | Training R2 0.508448 | Validation loss 13.889879 | Validation R2 0.445782\n",
            "          Best loss 13.889879 | Best epoch 0015\n",
            "          \n",
            "100%|##########| 672/672 [04:46<00:00,  2.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([33.4062, 45.7921, 44.3150, 42.8444, 38.4714, 51.1083, 44.6173, 38.2282,\n",
            "        41.4508, 33.1183, 43.8642, 26.2220, 34.4036, 24.6529, 30.0550, 23.5997,\n",
            "        28.8094, 21.6657, 26.8286, 18.9788, 24.0048, 18.7110, 20.9831],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([66.9750, 34.8300, 30.4850, 27.1220, 19.3810, 59.4210, 39.4690, 28.2220,\n",
            "        45.4640, 32.5130, 71.1690, 34.2430, 72.7160, 35.0360, 72.9860, 35.1970,\n",
            "        73.1260, 35.2700, 73.7120, 35.5420, 73.9550, 35.6660, 66.9750],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0016 | Training loss 13.523159 | Training R2 0.533908 | Validation loss 13.310001 | Validation R2 0.491091\n",
            "          Best loss 13.310001 | Best epoch 0016\n",
            "          \n",
            "\n",
            "          Epoch 0016 | Training loss 13.523159 | Training R2 0.533908 | Validation loss 13.310001 | Validation R2 0.491091\n",
            "          Best loss 13.310001 | Best epoch 0016\n",
            "          \n",
            "100%|##########| 672/672 [04:44<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([13.6608, 73.8658, 50.0054, 12.0001, 60.0117, 30.5455, 13.8400, 39.0830,\n",
            "        27.2152, 13.7561], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([18.0000, 80.3400, 25.8200,  4.2027, 84.0030, 27.2700,  4.4388, 82.8660,\n",
            "        26.9150,  4.3809], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0017 | Training loss 13.309327 | Training R2 0.548531 | Validation loss 13.026054 | Validation R2 0.512573\n",
            "          Best loss 13.026054 | Best epoch 0017\n",
            "          \n",
            "\n",
            "          Epoch 0017 | Training loss 13.309327 | Training R2 0.548531 | Validation loss 13.026054 | Validation R2 0.512573\n",
            "          Best loss 13.026054 | Best epoch 0017\n",
            "          \n",
            "100%|##########| 672/672 [04:45<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8.2451, 25.4013, 11.7649,  8.2381, 27.4235, 18.4464, 15.8813, 12.6014,\n",
            "         8.5868], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([17.2550, 16.6050,  5.5696,  2.1836, 53.8670, 17.2450, 10.7980,  5.7840,\n",
            "         2.2677], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0018 | Training loss 13.005368 | Training R2 0.568917 | Validation loss 12.941817 | Validation R2 0.518857\n",
            "          Best loss 12.941817 | Best epoch 0018\n",
            "          \n",
            "\n",
            "          Epoch 0018 | Training loss 13.005368 | Training R2 0.568917 | Validation loss 12.941817 | Validation R2 0.518857\n",
            "          Best loss 12.941817 | Best epoch 0018\n",
            "          \n",
            "100%|##########| 672/672 [04:46<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-3.2930, 41.1100, 12.9715,  9.2845,  7.5195, 30.1203, 22.5275, 13.2624,\n",
            "        11.1938, 29.7901, 17.8630, 15.5830, 12.9240, 21.6705, 17.9947, 14.4187],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 0.7684, 22.7900,  2.1049,  0.8118,  0.5042, 22.8300,  5.4673,  0.8133,\n",
            "         0.5051, 28.9870,  4.3086,  1.6618,  0.5051, 21.5700,  5.1656,  0.7684],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0019 | Training loss 12.462146 | Training R2 0.604177 | Validation loss 12.138934 | Validation R2 0.576703\n",
            "          Best loss 12.138934 | Best epoch 0019\n",
            "          \n",
            "\n",
            "          Epoch 0019 | Training loss 12.462146 | Training R2 0.604177 | Validation loss 12.138934 | Validation R2 0.576703\n",
            "          Best loss 12.138934 | Best epoch 0019\n",
            "          \n",
            "100%|##########| 672/672 [04:48<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 3.2754, 64.2589, 37.9990,  3.2725, 24.9393,  5.3459], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor([ 1.5969, 68.9360, 20.1160,  1.3031, 20.2650,  1.3127], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0020 | Training loss 12.032800 | Training R2 0.630981 | Validation loss 11.731411 | Validation R2 0.604647\n",
            "          Best loss 11.731411 | Best epoch 0020\n",
            "          \n",
            "\n",
            "          Epoch 0020 | Training loss 12.032800 | Training R2 0.630981 | Validation loss 11.731411 | Validation R2 0.604647\n",
            "          Best loss 11.731411 | Best epoch 0020\n",
            "          \n",
            "100%|##########| 672/672 [04:50<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2.9406, 61.2473, 28.9992,  3.8048, 22.1847,  5.6358], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor([ 2.0389, 55.6560, 16.1950,  2.1895, 15.9180,  2.1521], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0021 | Training loss 11.403233 | Training R2 0.668586 | Validation loss 11.126586 | Validation R2 0.644362\n",
            "          Best loss 11.126586 | Best epoch 0021\n",
            "          \n",
            "\n",
            "          Epoch 0021 | Training loss 11.403233 | Training R2 0.668586 | Validation loss 11.126586 | Validation R2 0.644362\n",
            "          Best loss 11.126586 | Best epoch 0021\n",
            "          \n",
            "100%|##########| 672/672 [04:51<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.8661, 33.6066, 13.1035,  3.6057, -0.9194, -1.3781, 10.9742,  3.5218,\n",
            "        -0.2657, -0.7849, 10.3535,  3.6867, -0.8698, -1.3888,  9.7753,  2.3312,\n",
            "        -1.1604, -1.5095,  9.1411,  2.5107, -0.7796,  6.1673,  3.0142, -0.1440,\n",
            "         7.4770,  3.0706,  0.8500,  0.5366,  2.6362,  0.9857, 11.5149,  6.6135,\n",
            "         3.2692,  1.5496], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 0.4168, 38.0910,  7.1683,  1.7787,  0.4414,  0.3499, 11.5080,  1.7944,\n",
            "         0.4453,  0.3530, 10.8300,  2.1303,  0.4190,  0.3322, 10.7820,  1.6812,\n",
            "         0.4172,  0.3307, 10.7730,  2.1190,  0.3304,  6.7693,  2.1190,  0.3304,\n",
            "        10.7810,  1.6811,  0.4171,  0.3307,  1.0556,  0.3304, 35.8960,  6.7693,\n",
            "         1.3316,  0.4168], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0022 | Training loss 10.749467 | Training R2 0.705497 | Validation loss 10.502131 | Validation R2 0.683161\n",
            "          Best loss 10.502131 | Best epoch 0022\n",
            "          \n",
            "\n",
            "          Epoch 0022 | Training loss 10.749467 | Training R2 0.705497 | Validation loss 10.502131 | Validation R2 0.683161\n",
            "          Best loss 10.502131 | Best epoch 0022\n",
            "          \n",
            "100%|##########| 672/672 [04:57<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([13.4830, 50.0187, 23.7006,  5.4426, 37.8579, 16.6934,  4.9872, 29.8659,\n",
            "        16.8404,  6.1422, 29.4313, 17.8592], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor([17.8830, 55.3190, 16.9870,  2.1271, 56.8470, 17.5230,  2.1942, 57.7130,\n",
            "        17.7900,  2.2277, 58.0120, 17.8830], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0023 | Training loss 9.863072 | Training R2 0.752064 | Validation loss 8.892389 | Validation R2 0.772846\n",
            "          Best loss 8.892389 | Best epoch 0023\n",
            "          \n",
            "\n",
            "          Epoch 0023 | Training loss 9.863072 | Training R2 0.752064 | Validation loss 8.892389 | Validation R2 0.772846\n",
            "          Best loss 8.892389 | Best epoch 0023\n",
            "          \n",
            "100%|##########| 672/672 [05:04<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 7.5230, 28.2083,  6.9638, 43.5712, 21.4790,  8.5901, 31.1690, 22.5257,\n",
            "         9.1989, 23.0525,  9.6945], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 9.4905, 23.3070,  3.3688, 62.3120, 21.5050,  3.5695, 43.4420, 24.6750,\n",
            "         3.5667, 25.0220,  3.6169], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0024 | Training loss 9.174282 | Training R2 0.785484 | Validation loss 8.411671 | Validation R2 0.796742\n",
            "          Best loss 8.411671 | Best epoch 0024\n",
            "          \n",
            "\n",
            "          Epoch 0024 | Training loss 9.174282 | Training R2 0.785484 | Validation loss 8.411671 | Validation R2 0.796742\n",
            "          Best loss 8.411671 | Best epoch 0024\n",
            "          \n",
            "100%|##########| 672/672 [05:27<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 6.6192, 48.7858, 18.1505,  3.0380, 40.1961, 15.6837,  3.2039, 16.1147,\n",
            "         4.3853, 36.3850, 16.3777,  4.8802], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor([ 6.8146, 52.2980, 17.1410,  3.0146, 53.6910, 17.8200,  3.1340, 18.0930,\n",
            "         3.1820, 52.6960, 17.4970,  3.0772], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0025 | Training loss 8.685740 | Training R2 0.807722 | Validation loss 8.016184 | Validation R2 0.815405\n",
            "          Best loss 8.016184 | Best epoch 0025\n",
            "          \n",
            "\n",
            "          Epoch 0025 | Training loss 8.685740 | Training R2 0.807722 | Validation loss 8.016184 | Validation R2 0.815405\n",
            "          Best loss 8.016184 | Best epoch 0025\n",
            "          \n",
            "100%|##########| 672/672 [06:36<00:00,  1.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([28.0076, 38.4045, 34.8358, 31.7636, 25.6699, 40.2830, 32.0294, 26.8187,\n",
            "        32.5924, 27.0152, 41.3812, 26.7896, 40.9982, 27.1342, 40.3140, 27.6385,\n",
            "        40.1446, 28.1381, 40.6030, 28.5903, 41.0018, 28.6758, 39.1366],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([66.9750, 34.8300, 30.4850, 27.1220, 19.3810, 59.4210, 39.4690, 28.2220,\n",
            "        45.4640, 32.5130, 71.1690, 34.2430, 72.7160, 35.0360, 72.9860, 35.1970,\n",
            "        73.1260, 35.2700, 73.7120, 35.5420, 73.9550, 35.6660, 66.9750],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0026 | Training loss 7.138400 | Training R2 0.870128 | Validation loss 6.485291 | Validation R2 0.879179\n",
            "          Best loss 6.485291 | Best epoch 0026\n",
            "          \n",
            "\n",
            "          Epoch 0026 | Training loss 7.138400 | Training R2 0.870128 | Validation loss 6.485291 | Validation R2 0.879179\n",
            "          Best loss 6.485291 | Best epoch 0026\n",
            "          \n",
            "100%|##########| 672/672 [07:31<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5.0187, 57.1289, 47.2150, 40.5393, 16.1645,  8.8857,  3.5374,  0.2072,\n",
            "        54.3989, 18.5376,  4.5431,  0.7809, 18.6194,  5.7077,  2.1814, 19.8678,\n",
            "         6.6993,  3.5592, 20.7630,  9.1452,  4.8885, 21.7630,  9.1384,  5.8849,\n",
            "        10.2070], device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([ 4.2077, 59.4320, 46.9050, 38.1280, 14.2580,  7.9220,  3.6186,  1.1171,\n",
            "        59.4890, 17.3990,  4.4157,  1.1207, 17.1950,  4.3640,  1.1075, 17.2810,\n",
            "         4.3856,  1.1130, 16.8630,  5.2057,  1.0861, 16.8560,  4.2779,  1.0857,\n",
            "         4.2077], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0027 | Training loss 7.282791 | Training R2 0.864820 | Validation loss 6.364136 | Validation R2 0.883651\n",
            "          Best loss 6.364136 | Best epoch 0027\n",
            "          \n",
            "\n",
            "          Epoch 0027 | Training loss 7.282791 | Training R2 0.864820 | Validation loss 6.364136 | Validation R2 0.883651\n",
            "          Best loss 6.364136 | Best epoch 0027\n",
            "          \n",
            "100%|##########| 672/672 [07:42<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8.3549, 41.2138, 34.2881, 29.6694, 25.6575, 15.7572, 47.6375, 30.6324,\n",
            "        18.5476, 50.3466, 31.9987, 18.9066, 51.0366, 43.9544, 18.6381, 43.7398,\n",
            "        18.6526, 43.3545, 18.4825, 18.2349, 49.8410, 18.2371, 42.3167, 18.1987],\n",
            "       device='cuda:0', grad_fn=<IndexBackward0>)\n",
            "tensor([12.5700, 31.8440, 25.2520, 20.7650, 17.3880, 10.5840, 40.6760, 22.8730,\n",
            "        13.9690, 43.5540, 24.6480, 15.0630, 44.0460, 35.6960, 15.2700, 35.8460,\n",
            "        15.3380, 35.8950, 15.3590, 15.2690, 43.9280, 15.2390, 35.5910, 15.2300],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0028 | Training loss 6.356060 | Training R2 0.897035 | Validation loss 5.972003 | Validation R2 0.897547\n",
            "          Best loss 5.972003 | Best epoch 0028\n",
            "          \n",
            "\n",
            "          Epoch 0028 | Training loss 6.356060 | Training R2 0.897035 | Validation loss 5.972003 | Validation R2 0.897547\n",
            "          Best loss 5.972003 | Best epoch 0028\n",
            "          \n",
            "100%|##########| 672/672 [07:49<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 6.9066, 82.5752, 25.0994,  7.8536,  3.5957, 18.4058,  4.5519, 59.7573,\n",
            "        22.0278,  7.7739,  5.0958, 68.1590,  5.6257, 21.3132,  9.0211,  6.2920,\n",
            "        67.1497, 21.4841,  9.6844,  6.7338, 66.4735,  9.6566,  6.8122, 64.8901,\n",
            "        21.4822,  9.3902,  6.9110, 62.5967, 20.4064,  9.1618,  6.9159, 52.6548,\n",
            "        20.6670,  9.3857,  6.9895, 60.4102, 23.1409,  9.2480], device='cuda:0',\n",
            "       grad_fn=<IndexBackward0>)\n",
            "tensor([ 6.1430, 77.5480, 24.0970,  7.7805,  2.9525, 17.9790,  3.0428, 55.8410,\n",
            "        21.1480,  6.8284,  3.0454, 63.6220,  2.9330, 20.3360,  6.5662,  2.9284,\n",
            "        63.5080, 20.3310,  6.5647,  2.9278, 63.5290,  6.5668,  2.9287, 62.7370,\n",
            "        20.0850,  6.4851,  2.8923, 61.1750, 19.5850,  6.3236,  2.8202, 51.6830,\n",
            "        19.5730,  6.3199,  2.8186, 59.4280, 22.3600,  6.1430], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:\n",
            "          Epoch 0029 | Training loss 6.130345 | Training R2 0.904218 | Validation loss 5.422178 | Validation R2 0.915544\n",
            "          Best loss 5.422178 | Best epoch 0029\n",
            "          \n",
            "\n",
            "          Epoch 0029 | Training loss 6.130345 | Training R2 0.904218 | Validation loss 5.422178 | Validation R2 0.915544\n",
            "          Best loss 5.422178 | Best epoch 0029\n",
            "          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1\n"
          ]
        }
      ],
      "source": [
        "fold, model = 1,1\n",
        "train, validate, test = datasplitter(data_complete, fold, model)\n",
        "ptnms = ['5010','5011','5012','5013','5014','5015','5016','5209','5210','5211','5212','5409','5410','5411','5412','5413','5414','5415','5416','5602','5603','5604','5605','5606','5607','5608','5609','5610']\n",
        "test_interp = pd.DataFrame()\n",
        "for ptnm in ptnms:\n",
        "    print(ptnm)\n",
        "    test_interp = pd.concat([test_interp, generate_interp(int(ptnm))], ignore_index=True)\n",
        "test_interp.to_csv(\"test_interp.csv\", index=False)\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "test.loc[test.CYCL > 5, \"AMT\"] = 0\n",
        "test.to_csv(\"test_nodosing.csv\", index=False)\n",
        "runtraining(1000, model, fold, 0.00005, 0.1, 30, 1e-4, False)\n",
        "runpredict(1000, model, fold, 0.00005, 0.1, 30, 1e-4, True)\n",
        "\n",
        "print(fold, model)"
      ],
      "id": "rn8tiB7Z9s2-"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h-rHKBt8lCDe",
        "outputId": "d5ef5ef4-4eaa-4d92-dc06-153b873062ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-a1547cc7bd9e>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"PTNM\"] = df[\"PTNM\"] + str(0.1)\n",
            "<ipython-input-13-a1547cc7bd9e>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"PTNM\"] = df[\"PTNM\"] + str(0.2)\n",
            "<ipython-input-13-a1547cc7bd9e>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"PTNM\"] = df[\"PTNM\"] + str(0.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5010\n",
            "5011\n",
            "5012\n",
            "5013\n",
            "5014\n",
            "5015\n",
            "5016\n",
            "5209\n",
            "5210\n",
            "5211\n",
            "5212\n",
            "5409\n",
            "5410\n",
            "5411\n",
            "5412\n",
            "5413\n",
            "5414\n",
            "5415\n",
            "5416\n",
            "5602\n",
            "5603\n",
            "5604\n",
            "5605\n",
            "5606\n",
            "5607\n",
            "5608\n",
            "5609\n",
            "5610\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        STUD  DSFQ      PTNM  CYCL    AMT   TIME   TFDS  PK_timeCourse  \\\n",
              "0     1000.0   3.0     00001   1.0  296.6    0.0    0.0        20.3820   \n",
              "1     1000.0   3.0     00001   1.0    0.0   24.0   24.0        73.1480   \n",
              "2     1000.0   3.0     00001   1.0    0.0  216.0  216.0        19.7640   \n",
              "3     1000.0   3.0     00001   1.0  288.0  504.0  504.0         3.2199   \n",
              "4     1000.0   3.0     00001   2.0    0.0  696.0  192.0        23.2100   \n",
              "...      ...   ...       ...   ...    ...    ...    ...            ...   \n",
              "7790  3000.0   3.0  001960.1   1.0    0.0   24.0   24.0        53.9210   \n",
              "7791  3000.0   3.0  001960.2   1.0  217.0    0.0    0.0         1.7780   \n",
              "7792  3000.0   3.0  001960.2   1.0    0.0   24.0   24.0        53.9210   \n",
              "7793  3000.0   3.0  001960.3   1.0  217.0    0.0    0.0         1.7780   \n",
              "7794  3000.0   3.0  001960.3   1.0    0.0   24.0   24.0        53.9210   \n",
              "\n",
              "             ID  PK_round1  \n",
              "0     100000001     20.382  \n",
              "1     100000001     73.148  \n",
              "2     100000001     19.764  \n",
              "3     100000001      0.000  \n",
              "4     100000001      0.000  \n",
              "...         ...        ...  \n",
              "7790  300000196     53.921  \n",
              "7791  300000196      1.778  \n",
              "7792  300000196     53.921  \n",
              "7793  300000196      1.778  \n",
              "7794  300000196     53.921  \n",
              "\n",
              "[7795 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-888a1dbb-9b3f-42d5-9559-aa98e46a1688\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STUD</th>\n",
              "      <th>DSFQ</th>\n",
              "      <th>PTNM</th>\n",
              "      <th>CYCL</th>\n",
              "      <th>AMT</th>\n",
              "      <th>TIME</th>\n",
              "      <th>TFDS</th>\n",
              "      <th>PK_timeCourse</th>\n",
              "      <th>ID</th>\n",
              "      <th>PK_round1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.3820</td>\n",
              "      <td>100000001</td>\n",
              "      <td>20.382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>73.1480</td>\n",
              "      <td>100000001</td>\n",
              "      <td>73.148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>216.0</td>\n",
              "      <td>19.7640</td>\n",
              "      <td>100000001</td>\n",
              "      <td>19.764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>1.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>3.2199</td>\n",
              "      <td>100000001</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>00001</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>696.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>23.2100</td>\n",
              "      <td>100000001</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7790</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>001960.1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.9210</td>\n",
              "      <td>300000196</td>\n",
              "      <td>53.921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7791</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>001960.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.7780</td>\n",
              "      <td>300000196</td>\n",
              "      <td>1.778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7792</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>001960.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.9210</td>\n",
              "      <td>300000196</td>\n",
              "      <td>53.921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7793</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>001960.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>217.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.7780</td>\n",
              "      <td>300000196</td>\n",
              "      <td>1.778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7794</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>001960.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>53.9210</td>\n",
              "      <td>300000196</td>\n",
              "      <td>53.921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7795 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-888a1dbb-9b3f-42d5-9559-aa98e46a1688')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-888a1dbb-9b3f-42d5-9559-aa98e46a1688 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-888a1dbb-9b3f-42d5-9559-aa98e46a1688');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "fold, model = 1,1\n",
        "train, validate, test = datasplitter(data_complete, fold, model)\n",
        "ptnms = ['5010','5011','5012','5013','5014','5015','5016','5209','5210','5211','5212','5409','5410','5411','5412','5413','5414','5415','5416','5602','5603','5604','5605','5606','5607','5608','5609','5610']\n",
        "test_interp = pd.DataFrame()\n",
        "for ptnm in ptnms:\n",
        "    print(ptnm)\n",
        "    test_interp = pd.concat([test_interp, generate_interp(int(ptnm))], ignore_index=True)\n",
        "test_interp.to_csv(\"test_interp.csv\", index=False)\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "test.loc[test.CYCL > 5, \"AMT\"] = 0\n",
        "test.to_csv(\"test_nodosing.csv\", index=False)\n",
        "x_train = train[[\"CYCL\", \"AMT\", \"TIME\", \"TFDS\"]]\n",
        "y_train = train[\"PK_timeCourse\"]\n",
        "x_val = validate[[\"CYCL\", \"AMT\", \"TIME\", \"TFDS\"]]\n",
        "y_val = validate[\"PK_timeCourse\"]\n",
        "x_test = test[[\"CYCL\", \"AMT\", \"TIME\", \"TFDS\"]]\n",
        "y_test = test[\"PK_timeCourse\"]\n",
        "train"
      ],
      "id": "h-rHKBt8lCDe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Ndx3oR6a5A",
        "outputId": "ac7ce76b-d69f-4e2e-e020-64c90742f428"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.8/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 50 rounds.\n",
            "[20]\ttraining's l2: 335.381\ttraining's rmse: 18.3134\tvalid_0's l2: 341.92\tvalid_0's rmse: 18.4911\n",
            "[40]\ttraining's l2: 288.729\ttraining's rmse: 16.992\tvalid_0's l2: 313.52\tvalid_0's rmse: 17.7065\n",
            "[60]\ttraining's l2: 250.552\ttraining's rmse: 15.8288\tvalid_0's l2: 293.22\tvalid_0's rmse: 17.1237\n",
            "[80]\ttraining's l2: 219.233\ttraining's rmse: 14.8065\tvalid_0's l2: 279.207\tvalid_0's rmse: 16.7095\n",
            "[100]\ttraining's l2: 193.427\ttraining's rmse: 13.9078\tvalid_0's l2: 270.042\tvalid_0's rmse: 16.433\n",
            "[120]\ttraining's l2: 172.24\ttraining's rmse: 13.124\tvalid_0's l2: 264.441\tvalid_0's rmse: 16.2616\n",
            "[140]\ttraining's l2: 154.808\ttraining's rmse: 12.4422\tvalid_0's l2: 262.174\tvalid_0's rmse: 16.1918\n",
            "[160]\ttraining's l2: 140.481\ttraining's rmse: 11.8525\tvalid_0's l2: 262.269\tvalid_0's rmse: 16.1947\n",
            "[180]\ttraining's l2: 128.623\ttraining's rmse: 11.3412\tvalid_0's l2: 264.735\tvalid_0's rmse: 16.2707\n",
            "Early stopping, best iteration is:\n",
            "[149]\ttraining's l2: 148.027\ttraining's rmse: 12.1666\tvalid_0's l2: 261.975\tvalid_0's rmse: 16.1856\n",
            "RMSE: 16.1856\n",
            "R2 Score: 0.31\n",
            "Pearson correlation coefficient: 0.5882\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Assuming you have trained the model and made predictions on the validation set\n",
        "\n",
        "\n",
        "params = {\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.005,\n",
        "    'num_leaves': 30,\n",
        "    'num_trees': 1000,\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse'\n",
        "}  \n",
        "\n",
        "model = lgb.LGBMRegressor(\n",
        "    boosting_type= 'gbdt',\n",
        "    learning_rate=0.005,\n",
        "    num_leaves= 30,\n",
        "    num_trees=1000,\n",
        "    objective='regression',\n",
        "    num_boost_round=10000,\n",
        "    early_stopping_rounds=50, \n",
        "    verbose_eval=100)\n",
        "\n",
        "model.fit(x_train,y_train,eval_set=[(x_test,y_test),(x_train,y_train)],\n",
        "          verbose=20,eval_metric='rmse')\n",
        "\n",
        "# train_data = lgb.Dataset(train_x, train_y)\n",
        "\n",
        "# # Train the model\n",
        "# model = lgb.train(train_data,boosting_type= 'gbdt',\n",
        "#     learning_rate=0.005,\n",
        "#     num_leaves= 30,\n",
        "#     num_trees=1000,\n",
        "#     objective='regression',\n",
        "#     metric='rmse',num_boost_round=10000, \n",
        "#     valid_sets=[train_data, (val_x, val_y)], \n",
        "#                   early_stopping_rounds=50, \n",
        "#                   verbose_eval=100)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Evaluate the model using RMSE\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R2 Score: {:.2f}\".format(r2))\n",
        "\n",
        "pearson_corr, _ = pearsonr(y_test, y_pred)\n",
        "print(f\"Pearson correlation coefficient: {pearson_corr:.4f}\")"
      ],
      "id": "q0Ndx3oR6a5A"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LSTM Model"
      ],
      "metadata": {
        "id": "BrxVpsVRuhn8"
      },
      "id": "BrxVpsVRuhn8"
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_train_x = train[[\"CYCL\", \"AMT\", \"TIME\", \"TFDS\", \"PK_round1\"]]\n",
        "lstm_train_y = train[[\"PK_timeCourse\"]]\n",
        "twentyelem = torch.flatten(torch.tensor(lstm_train_x[[\"TIME\", \"PK_round1\"]].head(20).values, dtype=torch.float32))"
      ],
      "metadata": {
        "id": "Ap_IX1suu0_q"
      },
      "id": "Ap_IX1suu0_q",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "      def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(LSTM, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # LSTM layers 1 and 2\n",
        "        self.lstm1 = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)\n",
        "        \n",
        "        # Decoder\n",
        "        self.decodernet = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 128),\n",
        "            nn.ReLU(), \n",
        "            nn.Linear(128, output_dim))\n",
        "        init_network_weights(self.decodernet)\n",
        "      \n",
        "      def forward(self, x):\n",
        "        output, _ = self.lstm1(x)\n",
        "        output = torch.tanh(output)\n",
        "        output, _ = self.lstm2(output)\n",
        "        output = torch.tanh(output)\n",
        "\n",
        "        #concatenate with PK_cycle1\n",
        "        print(output)\n",
        "        #output = torch.cat((output, twentyelem))\n",
        "\n",
        "        output = self.decodernet(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = 5\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "batch_size = 1\n",
        "learning_rate = 0.00005\n",
        "weight_decay = 0.1\n",
        "num_epochs = 30\n",
        "seq_len = 5\n",
        "\n",
        "#initializing everything\n",
        "model = LSTM(input_dim, hidden_dim, output_dim)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "#train loop\n",
        "for epoch in range(num_epochs):\n",
        "  optimizer.zero_grad()\n",
        "  x = torch.tensor(lstm_train_x.values, dtype=torch.float32)\n",
        "  y = torch.tensor(lstm_train_y.values, dtype=torch.float32)\n",
        "\n",
        "  output = model(x)\n",
        "  loss = criterion(output, y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "        \n",
        "  print('Epoch [{}/{}], Batch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, epoch+1, len(train), loss.item()**(0.5)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g2quF_8ugSY",
        "outputId": "c2d88c06-00b3-4175-a14d-af9e4382980c"
      },
      "id": "0g2quF_8ugSY",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0355,  0.0066, -0.1040,  ..., -0.0288,  0.0118, -0.0357],\n",
            "        [ 0.0595, -0.0376, -0.0706,  ...,  0.0110,  0.1287,  0.0078],\n",
            "        [ 0.0361, -0.0480, -0.1347,  ..., -0.0966,  0.0580,  0.0037],\n",
            "        ...,\n",
            "        [-0.0015, -0.0148, -0.1271,  ..., -0.0615,  0.1382,  0.0100],\n",
            "        [-0.0243,  0.0322, -0.1807,  ..., -0.1305,  0.1057,  0.0029],\n",
            "        [-0.0006, -0.0152, -0.1270,  ..., -0.0610,  0.1386,  0.0098]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [1/30], Batch [1/7795], Loss: 27.7238\n",
            "tensor([[ 3.5834e-02,  6.6643e-03, -1.0430e-01,  ..., -2.8557e-02,\n",
            "          1.1468e-02, -3.5510e-02],\n",
            "        [ 5.9606e-02, -3.7527e-02, -7.0859e-02,  ...,  1.1037e-02,\n",
            "          1.2809e-01,  8.2480e-03],\n",
            "        [ 3.5928e-02, -4.8620e-02, -1.3540e-01,  ..., -9.5884e-02,\n",
            "          5.7191e-02,  4.8181e-03],\n",
            "        ...,\n",
            "        [-9.9317e-04, -1.5084e-02, -1.2771e-01,  ..., -6.0964e-02,\n",
            "          1.3744e-01,  1.0547e-02],\n",
            "        [-2.3692e-02,  3.2045e-02, -1.8126e-01,  ..., -1.2988e-01,\n",
            "          1.0471e-01,  3.4618e-03],\n",
            "        [-1.4733e-04, -1.5456e-02, -1.2764e-01,  ..., -6.0421e-02,\n",
            "          1.3783e-01,  1.0360e-02]], grad_fn=<TanhBackward0>)\n",
            "Epoch [2/30], Batch [2/7795], Loss: 27.7143\n",
            "tensor([[ 0.0361,  0.0068, -0.1046,  ..., -0.0283,  0.0111, -0.0353],\n",
            "        [ 0.0597, -0.0375, -0.0711,  ...,  0.0111,  0.1275,  0.0087],\n",
            "        [ 0.0357, -0.0492, -0.1361,  ..., -0.0952,  0.0565,  0.0059],\n",
            "        ...,\n",
            "        [-0.0005, -0.0154, -0.1283,  ..., -0.0604,  0.1367,  0.0111],\n",
            "        [-0.0230,  0.0319, -0.1819,  ..., -0.1292,  0.1037,  0.0040],\n",
            "        [ 0.0003, -0.0157, -0.1283,  ..., -0.0598,  0.1370,  0.0109]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [3/30], Batch [3/7795], Loss: 27.7048\n",
            "tensor([[ 3.6408e-02,  6.8496e-03, -1.0483e-01,  ..., -2.8129e-02,\n",
            "          1.0711e-02, -3.5148e-02],\n",
            "        [ 5.9782e-02, -3.7456e-02, -7.1378e-02,  ...,  1.1218e-02,\n",
            "          1.2691e-01,  9.1802e-03],\n",
            "        [ 3.5418e-02, -4.9704e-02, -1.3683e-01,  ..., -9.4435e-02,\n",
            "          5.5743e-02,  7.0030e-03],\n",
            "        ...,\n",
            "        [ 6.8814e-05, -1.5623e-02, -1.2896e-01,  ..., -5.9779e-02,\n",
            "          1.3585e-01,  1.1571e-02],\n",
            "        [-2.2343e-02,  3.1718e-02, -1.8245e-01,  ..., -1.2858e-01,\n",
            "          1.0263e-01,  4.4897e-03],\n",
            "        [ 8.9787e-04, -1.5997e-02, -1.2890e-01,  ..., -5.9260e-02,\n",
            "          1.3623e-01,  1.1391e-02]], grad_fn=<TanhBackward0>)\n",
            "Epoch [4/30], Batch [4/7795], Loss: 27.6952\n",
            "tensor([[ 0.0367,  0.0069, -0.1051,  ..., -0.0279,  0.0103, -0.0350],\n",
            "        [ 0.0599, -0.0374, -0.0716,  ...,  0.0113,  0.1263,  0.0096],\n",
            "        [ 0.0352, -0.0502, -0.1376,  ..., -0.0937,  0.0550,  0.0081],\n",
            "        ...,\n",
            "        [ 0.0007, -0.0159, -0.1296,  ..., -0.0592,  0.1350,  0.0121],\n",
            "        [-0.0216,  0.0315, -0.1830,  ..., -0.1279,  0.1016,  0.0050],\n",
            "        [ 0.0015, -0.0163, -0.1295,  ..., -0.0587,  0.1354,  0.0119]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [5/30], Batch [5/7795], Loss: 27.6856\n",
            "tensor([[ 0.0370,  0.0070, -0.1053,  ..., -0.0277,  0.0099, -0.0348],\n",
            "        [ 0.0601, -0.0374, -0.0719,  ...,  0.0114,  0.1257,  0.0101],\n",
            "        [ 0.0349, -0.0508, -0.1383,  ..., -0.0929,  0.0543,  0.0092],\n",
            "        ...,\n",
            "        [ 0.0013, -0.0162, -0.1302,  ..., -0.0586,  0.1342,  0.0126],\n",
            "        [-0.0209,  0.0314, -0.1836,  ..., -0.1273,  0.1005,  0.0055],\n",
            "        [ 0.0021, -0.0166, -0.1302,  ..., -0.0581,  0.1346,  0.0124]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [6/30], Batch [6/7795], Loss: 27.6760\n",
            "tensor([[ 0.0373,  0.0070, -0.1056,  ..., -0.0275,  0.0096, -0.0346],\n",
            "        [ 0.0602, -0.0374, -0.0722,  ...,  0.0115,  0.1251,  0.0105],\n",
            "        [ 0.0347, -0.0514, -0.1390,  ..., -0.0922,  0.0536,  0.0102],\n",
            "        ...,\n",
            "        [ 0.0020, -0.0165, -0.1309,  ..., -0.0580,  0.1334,  0.0131],\n",
            "        [-0.0201,  0.0311, -0.1842,  ..., -0.1266,  0.0994,  0.0059],\n",
            "        [ 0.0028, -0.0169, -0.1309,  ..., -0.0575,  0.1338,  0.0129]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [7/30], Batch [7/7795], Loss: 27.6664\n",
            "tensor([[ 0.0376,  0.0071, -0.1059,  ..., -0.0274,  0.0092, -0.0345],\n",
            "        [ 0.0604, -0.0374, -0.0725,  ...,  0.0116,  0.1245,  0.0110],\n",
            "        [ 0.0345, -0.0519, -0.1398,  ..., -0.0914,  0.0529,  0.0113],\n",
            "        ...,\n",
            "        [ 0.0027, -0.0169, -0.1316,  ..., -0.0574,  0.1325,  0.0136],\n",
            "        [-0.0193,  0.0309, -0.1848,  ..., -0.1260,  0.0983,  0.0064],\n",
            "        [ 0.0035, -0.0172, -0.1315,  ..., -0.0569,  0.1329,  0.0134]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [8/30], Batch [8/7795], Loss: 27.6567\n",
            "tensor([[ 0.0378,  0.0071, -0.1061,  ..., -0.0272,  0.0088, -0.0343],\n",
            "        [ 0.0606, -0.0375, -0.0728,  ...,  0.0117,  0.1238,  0.0114],\n",
            "        [ 0.0342, -0.0525, -0.1405,  ..., -0.0906,  0.0522,  0.0124],\n",
            "        ...,\n",
            "        [ 0.0034, -0.0172, -0.1323,  ..., -0.0568,  0.1317,  0.0140],\n",
            "        [-0.0186,  0.0307, -0.1855,  ..., -0.1254,  0.0972,  0.0069],\n",
            "        [ 0.0041, -0.0176, -0.1322,  ..., -0.0564,  0.1321,  0.0139]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [9/30], Batch [9/7795], Loss: 27.6470\n",
            "tensor([[ 0.0381,  0.0071, -0.1064,  ..., -0.0270,  0.0084, -0.0342],\n",
            "        [ 0.0608, -0.0375, -0.0731,  ...,  0.0118,  0.1232,  0.0118],\n",
            "        [ 0.0340, -0.0531, -0.1413,  ..., -0.0898,  0.0515,  0.0134],\n",
            "        ...,\n",
            "        [ 0.0041, -0.0176, -0.1330,  ..., -0.0563,  0.1308,  0.0145],\n",
            "        [-0.0178,  0.0304, -0.1861,  ..., -0.1247,  0.0961,  0.0073],\n",
            "        [ 0.0048, -0.0180, -0.1330,  ..., -0.0558,  0.1312,  0.0144]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [10/30], Batch [10/7795], Loss: 27.6373\n",
            "tensor([[ 0.0384,  0.0071, -0.1067,  ..., -0.0269,  0.0079, -0.0340],\n",
            "        [ 0.0611, -0.0375, -0.0734,  ...,  0.0119,  0.1226,  0.0123],\n",
            "        [ 0.0338, -0.0537, -0.1421,  ..., -0.0890,  0.0508,  0.0145],\n",
            "        ...,\n",
            "        [ 0.0048, -0.0180, -0.1337,  ..., -0.0557,  0.1299,  0.0150],\n",
            "        [-0.0170,  0.0302, -0.1867,  ..., -0.1241,  0.0950,  0.0078],\n",
            "        [ 0.0056, -0.0183, -0.1337,  ..., -0.0553,  0.1303,  0.0149]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [11/30], Batch [11/7795], Loss: 27.6276\n",
            "tensor([[ 0.0387,  0.0070, -0.1070,  ..., -0.0267,  0.0075, -0.0339],\n",
            "        [ 0.0613, -0.0376, -0.0738,  ...,  0.0120,  0.1219,  0.0127],\n",
            "        [ 0.0336, -0.0544, -0.1429,  ..., -0.0882,  0.0501,  0.0155],\n",
            "        ...,\n",
            "        [ 0.0055, -0.0184, -0.1345,  ..., -0.0551,  0.1290,  0.0155],\n",
            "        [-0.0162,  0.0299, -0.1874,  ..., -0.1235,  0.0938,  0.0082],\n",
            "        [ 0.0063, -0.0188, -0.1345,  ..., -0.0547,  0.1294,  0.0154]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [12/30], Batch [12/7795], Loss: 27.6179\n",
            "tensor([[ 0.0390,  0.0070, -0.1072,  ..., -0.0266,  0.0071, -0.0337],\n",
            "        [ 0.0615, -0.0377, -0.0741,  ...,  0.0121,  0.1213,  0.0131],\n",
            "        [ 0.0334, -0.0550, -0.1437,  ..., -0.0874,  0.0494,  0.0166],\n",
            "        ...,\n",
            "        [ 0.0063, -0.0188, -0.1353,  ..., -0.0546,  0.1281,  0.0160],\n",
            "        [-0.0154,  0.0296, -0.1881,  ..., -0.1230,  0.0927,  0.0087],\n",
            "        [ 0.0070, -0.0192, -0.1353,  ..., -0.0542,  0.1285,  0.0158]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [13/30], Batch [13/7795], Loss: 27.6082\n",
            "tensor([[ 0.0393,  0.0069, -0.1075,  ..., -0.0264,  0.0067, -0.0335],\n",
            "        [ 0.0618, -0.0378, -0.0745,  ...,  0.0122,  0.1206,  0.0134],\n",
            "        [ 0.0332, -0.0557, -0.1445,  ..., -0.0866,  0.0487,  0.0176],\n",
            "        ...,\n",
            "        [ 0.0070, -0.0193, -0.1361,  ..., -0.0541,  0.1272,  0.0165],\n",
            "        [-0.0146,  0.0293, -0.1888,  ..., -0.1224,  0.0915,  0.0092],\n",
            "        [ 0.0078, -0.0196, -0.1361,  ..., -0.0537,  0.1276,  0.0163]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [14/30], Batch [14/7795], Loss: 27.5984\n",
            "tensor([[ 0.0396,  0.0068, -0.1078,  ..., -0.0263,  0.0063, -0.0334],\n",
            "        [ 0.0620, -0.0380, -0.0748,  ...,  0.0123,  0.1200,  0.0138],\n",
            "        [ 0.0330, -0.0564, -0.1453,  ..., -0.0859,  0.0480,  0.0186],\n",
            "        ...,\n",
            "        [ 0.0077, -0.0198, -0.1369,  ..., -0.0536,  0.1263,  0.0170],\n",
            "        [-0.0138,  0.0289, -0.1895,  ..., -0.1219,  0.0904,  0.0096],\n",
            "        [ 0.0085, -0.0201, -0.1369,  ..., -0.0532,  0.1267,  0.0168]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [15/30], Batch [15/7795], Loss: 27.5887\n",
            "tensor([[ 0.0399,  0.0067, -0.1080,  ..., -0.0262,  0.0059, -0.0332],\n",
            "        [ 0.0623, -0.0382, -0.0752,  ...,  0.0125,  0.1193,  0.0142],\n",
            "        [ 0.0328, -0.0571, -0.1461,  ..., -0.0851,  0.0472,  0.0196],\n",
            "        ...,\n",
            "        [ 0.0085, -0.0203, -0.1378,  ..., -0.0531,  0.1254,  0.0175],\n",
            "        [-0.0130,  0.0285, -0.1902,  ..., -0.1213,  0.0892,  0.0101],\n",
            "        [ 0.0092, -0.0207, -0.1378,  ..., -0.0527,  0.1257,  0.0173]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [16/30], Batch [16/7795], Loss: 27.5789\n",
            "tensor([[ 0.0401,  0.0066, -0.1083,  ..., -0.0261,  0.0056, -0.0331],\n",
            "        [ 0.0626, -0.0384, -0.0756,  ...,  0.0126,  0.1186,  0.0145],\n",
            "        [ 0.0327, -0.0578, -0.1469,  ..., -0.0843,  0.0465,  0.0206],\n",
            "        ...,\n",
            "        [ 0.0092, -0.0209, -0.1387,  ..., -0.0527,  0.1244,  0.0179],\n",
            "        [-0.0122,  0.0281, -0.1909,  ..., -0.1208,  0.0881,  0.0105],\n",
            "        [ 0.0100, -0.0212, -0.1387,  ..., -0.0523,  0.1248,  0.0178]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [17/30], Batch [17/7795], Loss: 27.5692\n",
            "tensor([[ 0.0404,  0.0065, -0.1086,  ..., -0.0260,  0.0052, -0.0329],\n",
            "        [ 0.0629, -0.0386, -0.0760,  ...,  0.0127,  0.1180,  0.0148],\n",
            "        [ 0.0325, -0.0586, -0.1478,  ..., -0.0835,  0.0458,  0.0216],\n",
            "        ...,\n",
            "        [ 0.0100, -0.0214, -0.1396,  ..., -0.0522,  0.1235,  0.0184],\n",
            "        [-0.0114,  0.0277, -0.1916,  ..., -0.1204,  0.0869,  0.0110],\n",
            "        [ 0.0107, -0.0218, -0.1396,  ..., -0.0518,  0.1239,  0.0183]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [18/30], Batch [18/7795], Loss: 27.5596\n",
            "tensor([[ 0.0407,  0.0064, -0.1088,  ..., -0.0258,  0.0048, -0.0327],\n",
            "        [ 0.0632, -0.0388, -0.0765,  ...,  0.0128,  0.1173,  0.0151],\n",
            "        [ 0.0324, -0.0593, -0.1486,  ..., -0.0828,  0.0451,  0.0225],\n",
            "        ...,\n",
            "        [ 0.0107, -0.0221, -0.1405,  ..., -0.0518,  0.1225,  0.0189],\n",
            "        [-0.0106,  0.0272, -0.1924,  ..., -0.1199,  0.0857,  0.0115],\n",
            "        [ 0.0114, -0.0224, -0.1406,  ..., -0.0514,  0.1229,  0.0187]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [19/30], Batch [19/7795], Loss: 27.5500\n",
            "tensor([[ 0.0410,  0.0063, -0.1091,  ..., -0.0257,  0.0044, -0.0326],\n",
            "        [ 0.0635, -0.0391, -0.0770,  ...,  0.0129,  0.1167,  0.0154],\n",
            "        [ 0.0323, -0.0601, -0.1495,  ..., -0.0820,  0.0444,  0.0235],\n",
            "        ...,\n",
            "        [ 0.0115, -0.0227, -0.1415,  ..., -0.0514,  0.1216,  0.0193],\n",
            "        [-0.0098,  0.0268, -0.1931,  ..., -0.1195,  0.0845,  0.0119],\n",
            "        [ 0.0122, -0.0231, -0.1416,  ..., -0.0510,  0.1219,  0.0192]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [20/30], Batch [20/7795], Loss: 27.5404\n",
            "tensor([[ 0.0413,  0.0062, -0.1094,  ..., -0.0256,  0.0040, -0.0324],\n",
            "        [ 0.0639, -0.0393, -0.0774,  ...,  0.0131,  0.1160,  0.0157],\n",
            "        [ 0.0322, -0.0609, -0.1503,  ..., -0.0813,  0.0436,  0.0244],\n",
            "        ...,\n",
            "        [ 0.0123, -0.0234, -0.1426,  ..., -0.0510,  0.1206,  0.0197],\n",
            "        [-0.0090,  0.0263, -0.1939,  ..., -0.1190,  0.0833,  0.0124],\n",
            "        [ 0.0130, -0.0238, -0.1426,  ..., -0.0507,  0.1209,  0.0196]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [21/30], Batch [21/7795], Loss: 27.5309\n",
            "tensor([[ 0.0416,  0.0061, -0.1096,  ..., -0.0255,  0.0036, -0.0323],\n",
            "        [ 0.0642, -0.0396, -0.0780,  ...,  0.0132,  0.1153,  0.0160],\n",
            "        [ 0.0321, -0.0617, -0.1512,  ..., -0.0805,  0.0429,  0.0253],\n",
            "        ...,\n",
            "        [ 0.0131, -0.0241, -0.1436,  ..., -0.0507,  0.1196,  0.0202],\n",
            "        [-0.0082,  0.0258, -0.1947,  ..., -0.1186,  0.0821,  0.0128],\n",
            "        [ 0.0138, -0.0245, -0.1436,  ..., -0.0503,  0.1199,  0.0200]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [22/30], Batch [22/7795], Loss: 27.5214\n",
            "tensor([[ 0.0418,  0.0059, -0.1099,  ..., -0.0254,  0.0032, -0.0321],\n",
            "        [ 0.0646, -0.0399, -0.0785,  ...,  0.0134,  0.1146,  0.0162],\n",
            "        [ 0.0320, -0.0625, -0.1521,  ..., -0.0798,  0.0422,  0.0262],\n",
            "        ...,\n",
            "        [ 0.0138, -0.0249, -0.1447,  ..., -0.0503,  0.1186,  0.0206],\n",
            "        [-0.0073,  0.0252, -0.1955,  ..., -0.1182,  0.0809,  0.0132],\n",
            "        [ 0.0145, -0.0252, -0.1447,  ..., -0.0499,  0.1189,  0.0205]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [23/30], Batch [23/7795], Loss: 27.5119\n",
            "tensor([[ 0.0421,  0.0058, -0.1102,  ..., -0.0252,  0.0028, -0.0319],\n",
            "        [ 0.0650, -0.0402, -0.0791,  ...,  0.0135,  0.1139,  0.0164],\n",
            "        [ 0.0319, -0.0634, -0.1530,  ..., -0.0791,  0.0415,  0.0270],\n",
            "        ...,\n",
            "        [ 0.0147, -0.0257, -0.1458,  ..., -0.0500,  0.1176,  0.0210],\n",
            "        [-0.0065,  0.0246, -0.1963,  ..., -0.1178,  0.0797,  0.0137],\n",
            "        [ 0.0153, -0.0260, -0.1458,  ..., -0.0496,  0.1179,  0.0209]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [24/30], Batch [24/7795], Loss: 27.5023\n",
            "tensor([[ 0.0424,  0.0057, -0.1105,  ..., -0.0251,  0.0024, -0.0318],\n",
            "        [ 0.0654, -0.0405, -0.0796,  ...,  0.0137,  0.1133,  0.0167],\n",
            "        [ 0.0319, -0.0642, -0.1539,  ..., -0.0784,  0.0407,  0.0278],\n",
            "        ...,\n",
            "        [ 0.0155, -0.0265, -0.1469,  ..., -0.0496,  0.1165,  0.0214],\n",
            "        [-0.0057,  0.0240, -0.1972,  ..., -0.1175,  0.0785,  0.0141],\n",
            "        [ 0.0162, -0.0268, -0.1470,  ..., -0.0493,  0.1169,  0.0213]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [25/30], Batch [25/7795], Loss: 27.4929\n",
            "tensor([[ 0.0427,  0.0056, -0.1107,  ..., -0.0250,  0.0020, -0.0316],\n",
            "        [ 0.0658, -0.0409, -0.0802,  ...,  0.0138,  0.1126,  0.0169],\n",
            "        [ 0.0319, -0.0651, -0.1548,  ..., -0.0777,  0.0400,  0.0287],\n",
            "        ...,\n",
            "        [ 0.0163, -0.0274, -0.1481,  ..., -0.0493,  0.1155,  0.0218],\n",
            "        [-0.0048,  0.0234, -0.1980,  ..., -0.1171,  0.0773,  0.0145],\n",
            "        [ 0.0170, -0.0277, -0.1482,  ..., -0.0490,  0.1158,  0.0217]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [26/30], Batch [26/7795], Loss: 27.4834\n",
            "tensor([[ 0.0430,  0.0054, -0.1110,  ..., -0.0249,  0.0016, -0.0315],\n",
            "        [ 0.0663, -0.0412, -0.0808,  ...,  0.0140,  0.1119,  0.0171],\n",
            "        [ 0.0319, -0.0660, -0.1558,  ..., -0.0771,  0.0392,  0.0294],\n",
            "        ...,\n",
            "        [ 0.0171, -0.0283, -0.1493,  ..., -0.0490,  0.1144,  0.0222],\n",
            "        [-0.0040,  0.0228, -0.1988,  ..., -0.1167,  0.0760,  0.0150],\n",
            "        [ 0.0178, -0.0286, -0.1494,  ..., -0.0487,  0.1148,  0.0221]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [27/30], Batch [27/7795], Loss: 27.4739\n",
            "tensor([[ 0.0433,  0.0053, -0.1113,  ..., -0.0248,  0.0012, -0.0313],\n",
            "        [ 0.0667, -0.0416, -0.0815,  ...,  0.0142,  0.1112,  0.0173],\n",
            "        [ 0.0318, -0.0669, -0.1567,  ..., -0.0764,  0.0385,  0.0302],\n",
            "        ...,\n",
            "        [ 0.0180, -0.0292, -0.1505,  ..., -0.0487,  0.1133,  0.0226],\n",
            "        [-0.0031,  0.0221, -0.1997,  ..., -0.1164,  0.0748,  0.0154],\n",
            "        [ 0.0187, -0.0295, -0.1506,  ..., -0.0484,  0.1137,  0.0225]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [28/30], Batch [28/7795], Loss: 27.4644\n",
            "tensor([[ 0.0436,  0.0052, -0.1116,  ..., -0.0247,  0.0008, -0.0311],\n",
            "        [ 0.0672, -0.0420, -0.0821,  ...,  0.0143,  0.1105,  0.0174],\n",
            "        [ 0.0319, -0.0678, -0.1576,  ..., -0.0758,  0.0378,  0.0309],\n",
            "        ...,\n",
            "        [ 0.0189, -0.0302, -0.1518,  ..., -0.0484,  0.1122,  0.0230],\n",
            "        [-0.0022,  0.0214, -0.2006,  ..., -0.1161,  0.0735,  0.0158],\n",
            "        [ 0.0196, -0.0305, -0.1518,  ..., -0.0481,  0.1126,  0.0229]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [29/30], Batch [29/7795], Loss: 27.4549\n",
            "tensor([[ 0.0439,  0.0050, -0.1118,  ..., -0.0246,  0.0003, -0.0310],\n",
            "        [ 0.0676, -0.0423, -0.0828,  ...,  0.0145,  0.1097,  0.0176],\n",
            "        [ 0.0319, -0.0688, -0.1585,  ..., -0.0751,  0.0370,  0.0316],\n",
            "        ...,\n",
            "        [ 0.0198, -0.0312, -0.1531,  ..., -0.0482,  0.1111,  0.0234],\n",
            "        [-0.0013,  0.0207, -0.2015,  ..., -0.1157,  0.0722,  0.0162],\n",
            "        [ 0.0205, -0.0315, -0.1531,  ..., -0.0478,  0.1114,  0.0232]],\n",
            "       grad_fn=<TanhBackward0>)\n",
            "Epoch [30/30], Batch [30/7795], Loss: 27.4454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjBgO0B85Cxy"
      },
      "outputs": [],
      "source": [
        "# for fold in np.arange(1,6):\n",
        "#   for model in np.arange(1,6):\n",
        "#      train, validate, test = datasplitter(data_complete, fold, model)\n",
        "#      runtraining(1000, model, fold, 0.00005, 0.1, 30, 1e-4, True)\n",
        "#      runpredict(1000, model, fold, 0.00005, 0.1, 30, 1e-4, True)\n",
        "\n",
        "#      print(fold, model)"
      ],
      "id": "QjBgO0B85Cxy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "0ELxbkYVkd_P",
        "outputId": "5b6db2c6-5e51-48c0-8604-1872d1c96255"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-61a47502edc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomplete_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'complete_data' is not defined"
          ]
        }
      ],
      "source": [
        "complete_data"
      ],
      "id": "0ELxbkYVkd_P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l7jtZ9a31ue"
      },
      "outputs": [],
      "source": [
        "for fold in np.arange(1,6):\n",
        "  for model in np.arange(1,6):\n",
        "     train, validate, test = datasplitter(data_complete, fold, model)\n",
        "     \n",
        "\n",
        "     print(fold, model)"
      ],
      "id": "3l7jtZ9a31ue"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}