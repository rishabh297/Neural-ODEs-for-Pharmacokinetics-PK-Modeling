{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca4d8b4",
   "metadata": {},
   "source": [
    "# Code Annotations/Analysis of Model + Training/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05b844ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torch.nn.modules.rnn import GRU, LSTM, RNN\n",
    "import utils\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import SystemRandom\n",
    "from tqdm import tqdm\n",
    "\n",
    "from args import args\n",
    "import torch.optim as optim\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "\n",
    "from data_parse import parse_tdm1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311e48d",
   "metadata": {},
   "source": [
    "## model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052fa25a",
   "metadata": {},
   "source": [
    "The encoder class defines an encoder network following variational autoencoder concept. This means that the inputs are mapped to a distribution rather than a deterministic outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5912a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    #initializes attributes of instances of encoder\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, device=torch.device(\"cpu\")):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "\n",
    "    #Sets up a sequential layers for network. Encoders analyzes a single element of the input sequence, \"retains/encodes\" important info about that element, and propogates forward. \n",
    "        self.hiddens_to_output = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            #ReLU activation function is similar to SELU except it takes on binary values and can result in dead neurons, causing them to not be used for predicing outputs from features.\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim),\n",
    "        )\n",
    "        #utils function that serves similar purpose as for loop in ODEFunc class. However, this function initializes biases as a 0 constant while weights are sampled from gaussian dist.\n",
    "        utils.init_network_weights(self.hiddens_to_output, std=0.001)\n",
    "\n",
    "        #nn.GRU applies a \"pre-built\" GRU to a given input; the GRU \"scans\" through the time series data in reverse and encodes the relevant data into a 12-element array. This array is fed into the ODEFunc network to define the mean and standard deviation of the latent state distributions which z_t0 is sampled from. \n",
    "        # self.rnn = nn.RNN(self.input_dim, self.hidden_dim, nonlinearity=\"relu\").to(device)\n",
    "        self.rnn = nn.GRU(self.input_dim, self.hidden_dim).to(device)\n",
    "\n",
    "    #defines forward pass of encoder\n",
    "    def forward(self, data):\n",
    "        #permutes data to make necessary dimensional changes\n",
    "        data = data.permute(1, 0, 2)\n",
    "        #reverses data to allow GRU to scan through time series data in reverse fashion (why?)\n",
    "        data = utils.reverse(data)\n",
    "        #sends input data through GRU\n",
    "        output_rnn, _ = self.rnn(data)\n",
    "        #print(output_rnn)\n",
    "        #takes in the data scanned in reverse (done by GRU) and feeds through \n",
    "        outputs = self.hiddens_to_output(output_rnn[-1])\n",
    "        #print(outputs)\n",
    "        \n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4153e",
   "metadata": {},
   "source": [
    "The ODEFunc class is a neural network responsible for uncovering the underlying differential equation for the dyanmical system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9421a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "\n",
    "    #initializes neural network with desired dimensions\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ODEFunc, self).__init__()\n",
    "\n",
    "        #nn.Sequential is a method that allows the creation of layers in the neural network. The method itself acts as a \"container\" for the layers/modules inside the network.\n",
    "        self.net = nn.Sequential(\n",
    "            #layers in a neural network are nothing but a series of linear transformations on our input matrix (y = xAt + b). nn.Linear forms a \"linear layer\" which applies learnable weights (x) and biases (b) to our input data (At). The dimensionality of data often changes hence the allowance of input_dim and hidden-dim. \n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            #nn.SeLu is an activation function. Activation functions determine the weighted \"importance\" of features in the input data. This adds non-linearity to our model which allows it to be more complex than simple linear regression. SELU specifically allows for self-normalizing neural nets and tackles the vanishing gradient problem.\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "        # this for loop interates through every linear layer (set of layers is returned by calling self.net.modulesi) in the neural network we defined above and initializes weights/biases of input feature\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                #if a module (layer) in our network is a linear layer and not an activation function, this randomly initializes our input tensor of weights of each layer (m.weights) with values sampled from a Gaussian distribution with mean 0 and SD 0.001. This mitigates the vanishing/exploding gradient problem.\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.001)\n",
    "                # if a module is a linear layer, then the input tensor (tensor containing biases of the layer) are all initialized to 0.5\n",
    "                nn.init.constant_(m.bias, val=0.5)\n",
    "\n",
    "    #feeds our input data through our network (self.net)\n",
    "    def forward(self, t, x):\n",
    "        # print(x)\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c227b",
   "metadata": {},
   "source": [
    "Classifier initializes and defines a decoder network that takes in the sequence of z_t's outputted by the ODEFunc network. It then generates the predictions from the output of the ODE solver and the first dosing observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "484c3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializes and defines a decoder network that takes in the sequence of z_t's outputted by the ODEFunc network. It then generates the predictions from the output of the ODE solver and the first dosing observations.\n",
    "class Classifier(nn.Module):\n",
    "\n",
    "    #init method creates another set of sequential modules with 1 fully connected layer and 32 hidden units\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim + 20, 32),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "        \n",
    "        #follows same weight and bias initialization protocol as the Encoder class\n",
    "        utils.init_network_weights(self.net, std=0.001)\n",
    "\n",
    "    #defines forward pass where z is the sequence of z_t's generated by the output of ODEFunc and cmax_time refers to the dosing information.\n",
    "    def forward(self, z, cmax_time):\n",
    "        #repeates dosing information along given dimensions to match up with z\n",
    "        cmax_time = cmax_time.repeat(z.size(0), 1, 1)\n",
    "        #joins dosing info with sequence of z_t's and feeds in as input to decoder\n",
    "        z = torch.cat([z, cmax_time], 2)\n",
    "        return self.net(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944c0454",
   "metadata": {},
   "source": [
    "## run_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39f7d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tdm1_obj = parse_tdm1(device, phase=\"train\")\n",
    "input_dim = tdm1_obj[\"input_dim\"]\n",
    "hidden_dim = 128\n",
    "latent_dim = 6\n",
    "\n",
    "encoder = Encoder(input_dim=input_dim, output_dim=2 * latent_dim, hidden_dim=hidden_dim)\n",
    "ode_func = ODEFunc(input_dim=latent_dim, hidden_dim=16)\n",
    "classifier = Classifier(latent_dim=latent_dim, output_dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbb8603",
   "metadata": {},
   "source": [
    "tdm1_obj is a dictionary that contains a generator that outputs every \"data point\" when next( ) is called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79fa0e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dataloader': <generator object inf_generator at 0x7fd502abf040>,\n",
       " 'val_dataloader': <generator object inf_generator at 0x7fd502abf3c0>,\n",
       " 'n_train_batches': 656,\n",
       " 'n_val_batches': 56,\n",
       " 'input_dim': 5}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm1_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0331cf3f",
   "metadata": {},
   "source": [
    "Each next( ) returns a patient data point where each tensor contains the relevant information for each feature per patient\n",
    "- TFDS (time in hours between each dose)\n",
    "- AMT (dosing amount in milligrams)\n",
    "- TIME (time in hours since treatment started)\n",
    "- CYCL (current dosing cycle #)\n",
    "- PK (pk info for first cycle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfdc8005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([138.2],\n",
       " tensor([ 0.,  1.,  2.,  3.,  5.,  8., 11., 15., 18., 21., 23., 30., 38., 42.,\n",
       "         46., 53., 60., 63.]),\n",
       " tensor([[[0.0000e+00, 0.0000e+00, 1.0000e+00, 2.8690e+02, 1.6102e-01],\n",
       "          [2.4000e+01, 1.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00],\n",
       "          [4.8000e+01, 2.0000e+00, 1.0000e+00, 0.0000e+00, 7.4971e-01],\n",
       "          [7.2000e+01, 3.0000e+00, 1.0000e+00, 0.0000e+00, 6.0366e-01],\n",
       "          [1.2000e+02, 5.0000e+00, 1.0000e+00, 0.0000e+00, 4.2979e-01],\n",
       "          [1.9200e+02, 8.0000e+00, 1.0000e+00, 0.0000e+00, 2.7488e-01],\n",
       "          [2.6400e+02, 1.1000e+01, 1.0000e+00, 0.0000e+00, 1.7767e-01],\n",
       "          [3.6000e+02, 1.5000e+01, 1.0000e+00, 0.0000e+00, 9.9438e-02],\n",
       "          [4.3200e+02, 1.8000e+01, 1.0000e+00, 0.0000e+00, 6.4347e-02],\n",
       "          [0.0000e+00, 2.1000e+01, 2.0000e+00, 2.8510e+02, 0.0000e+00],\n",
       "          [4.8000e+01, 2.3000e+01, 2.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.1600e+02, 3.0000e+01, 2.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [4.0800e+02, 3.8000e+01, 2.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 4.2000e+01, 3.0000e+00, 2.8730e+02, 0.0000e+00],\n",
       "          [9.6000e+01, 4.6000e+01, 3.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.6400e+02, 5.3000e+01, 3.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [4.3200e+02, 6.0000e+01, 3.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 6.3000e+01, 4.0000e+00, 2.9560e+02, 0.0000e+00]]]),\n",
       " tensor([[[10.7920],\n",
       "          [67.0230],\n",
       "          [50.2480],\n",
       "          [40.4590],\n",
       "          [28.8060],\n",
       "          [18.4230],\n",
       "          [11.9080],\n",
       "          [ 6.6646],\n",
       "          [ 4.3127],\n",
       "          [ 2.7908],\n",
       "          [51.7870],\n",
       "          [16.5370],\n",
       "          [ 5.1780],\n",
       "          [ 2.8982],\n",
       "          [35.3890],\n",
       "          [12.4800],\n",
       "          [ 4.5195],\n",
       "          [ 2.9246]]]),\n",
       " tensor([[ 0.0000, 10.7920,  1.0000, 67.0230,  2.0000, 50.2480,  3.0000, 40.4590,\n",
       "           5.0000, 28.8060,  8.0000, 18.4230, 11.0000, 11.9080, 15.0000,  6.6646,\n",
       "          18.0000,  4.3127,  0.0000,  0.0000]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(tdm1_obj[\"train_dataloader\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57dc0d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (hiddens_to_output): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=12, bias=True)\n",
       "  )\n",
       "  (rnn): GRU(5, 128)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45988c83",
   "metadata": {},
   "source": [
    "Encoder Structure:\n",
    "- Data is fed through GRU to reversely scan the data\n",
    "    - GRU input dim: 5\n",
    "    - GRU output dim:128\n",
    "- Why is it fed through GRU?: Based on sample codes from Chen et al., the GRU is inferring the parameters of the governing ODE using a-posteriori likelihood estimation\n",
    "- Output of GRU is then fed through 2 linear layers \n",
    "- these two linear layers fall under \"hiddens_to_output\" which takes the given info from GRU and \"condenses\" it into a 12 element vector to be passed into ODEFunc\n",
    "- 12 element output:\n",
    "    - first 6 elements define the mean of latent distribution\n",
    "    - last 6 elements define var of latent distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b2900dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ODEFunc(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (3): SELU()\n",
       "    (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (5): SELU()\n",
       "    (6): Linear(in_features=16, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ode_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac6d20c",
   "metadata": {},
   "source": [
    "ODE solver function:\n",
    "- at every time step it takes in the time interval between curr_time and prev_time along with zti-1\n",
    "- outputs current zti\n",
    "- then odeint in run_predict/train integrates the dosing info and time interval\n",
    "- each layer has 16 neurons \n",
    "- output contains relevant zti "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36f8385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=26, out_features=32, bias=True)\n",
       "    (1): SELU()\n",
       "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1407c4",
   "metadata": {},
   "source": [
    "Classifier:\n",
    "- input is 26 because 20 are added to the 6 features and these 20 \"points\" correspond to the TIME and PK values of the first observational cycle\n",
    "- output dim is 1 which is prediction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c91d9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size defines how many training samples must be done before updating weights/biases of a node during backprop\n",
    "#epoch defines how many total backward passes we will do\n",
    "batches_per_epoch = tdm1_obj[\"n_train_batches\"]\n",
    "#sets L2 norm-squared (MSE) between predicted and actual as loss criterion\n",
    "criterion = nn.MSELoss().to(device=device)\n",
    "params = (list(encoder.parameters()) + \n",
    "          list(ode_func.parameters()) + \n",
    "          list(classifier.parameters()))\n",
    "#utilizing Adam optimization algorithm rather than SGD to overcome saddlepoints in data. It incorporates the idea of momentum by nudging weights/biases by the average running gradient rather than the gradient itself.\n",
    "optimizer = optim.Adam(params, lr=args.lr, weight_decay=args.l2)\n",
    "best_rmse = 0x7fffffff\n",
    "best_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6b2d389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 2.8305e-04, -7.2165e-04,  1.1129e-03, -2.5711e-04, -4.1860e-04,\n",
      "         -5.8494e-04],\n",
      "        [-4.7550e-04, -9.4963e-04, -8.0647e-04,  1.3770e-03,  1.4111e-03,\n",
      "          7.3048e-04],\n",
      "        [ 2.2337e-03,  1.8944e-04,  8.7430e-04, -8.5660e-04, -1.3127e-03,\n",
      "          8.1759e-04],\n",
      "        [ 1.3650e-04, -5.2175e-05, -7.9395e-04,  3.4341e-04,  6.9999e-05,\n",
      "          5.3275e-04],\n",
      "        [-5.6509e-04,  5.1907e-04, -1.6741e-03,  3.1920e-03,  6.9834e-04,\n",
      "         -4.1255e-04],\n",
      "        [ 3.0215e-04, -1.3714e-04,  4.3635e-04,  1.1569e-03,  4.8504e-04,\n",
      "          4.1208e-04],\n",
      "        [-1.4352e-04,  1.6234e-03,  1.2955e-03,  2.1052e-04,  3.0906e-03,\n",
      "          1.1878e-04],\n",
      "        [-1.7562e-03, -2.5700e-04, -3.0894e-04, -7.6726e-04,  1.0438e-03,\n",
      "         -7.7088e-04],\n",
      "        [-2.5061e-03,  9.4991e-04,  1.4287e-03, -2.0756e-04, -1.9781e-03,\n",
      "          2.8621e-03],\n",
      "        [-1.6183e-03,  4.4493e-04,  2.0488e-04, -7.3180e-04,  6.6896e-05,\n",
      "          1.0588e-03],\n",
      "        [ 4.9546e-04, -1.5225e-03, -1.1804e-03, -1.3646e-04, -7.9068e-04,\n",
      "          1.2944e-03],\n",
      "        [ 1.5838e-04, -3.0680e-05, -8.0064e-04, -3.8957e-04, -8.5942e-04,\n",
      "         -1.8312e-03],\n",
      "        [-6.9918e-04,  1.9608e-04,  8.4151e-04,  8.3248e-04, -2.7309e-04,\n",
      "         -1.1283e-03],\n",
      "        [-6.5301e-04, -6.8311e-04,  6.1696e-04,  5.0875e-04, -4.0292e-04,\n",
      "         -4.6968e-04],\n",
      "        [-2.2458e-03, -1.8926e-03, -6.0657e-04,  8.8552e-05,  1.4973e-04,\n",
      "          1.2571e-04],\n",
      "        [ 1.0163e-03,  5.2500e-04, -1.3426e-03, -2.7375e-04,  9.7412e-04,\n",
      "          9.5533e-05]], requires_grad=True), Parameter containing:\n",
      "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 2.4423e-03,  1.1381e-04,  1.3603e-03,  6.3156e-04, -7.1661e-04,\n",
      "         -6.2026e-04, -1.1329e-03, -6.0404e-04, -3.7628e-04,  3.3642e-04,\n",
      "         -6.9619e-04, -3.4440e-03, -2.2123e-04, -1.3365e-03, -6.0276e-04,\n",
      "         -2.0696e-03],\n",
      "        [-2.8250e-04,  1.2883e-03, -3.3239e-05,  1.1801e-03,  1.3299e-03,\n",
      "          7.8607e-04, -4.8808e-04, -1.5652e-03, -1.6279e-04,  7.8090e-04,\n",
      "          1.2941e-03, -5.7193e-04, -6.0732e-04, -1.5786e-03,  3.6021e-04,\n",
      "         -8.5763e-04],\n",
      "        [ 6.9146e-04,  1.1392e-03,  6.2525e-04,  2.0484e-03,  5.3863e-04,\n",
      "         -2.5410e-03,  8.1593e-04,  3.8285e-04,  4.7372e-04,  1.0852e-03,\n",
      "         -5.4736e-04, -4.5080e-04, -5.7371e-04,  8.1931e-05, -1.5677e-03,\n",
      "         -5.3850e-04],\n",
      "        [-3.9788e-04,  7.4388e-04,  1.4685e-04,  9.1981e-04, -1.3399e-03,\n",
      "          9.4831e-04,  1.2740e-04,  1.2580e-03, -3.8557e-04, -1.3460e-03,\n",
      "         -2.1504e-03, -3.6061e-04, -1.4052e-04,  1.7658e-03,  1.2324e-03,\n",
      "          1.4861e-03],\n",
      "        [-5.4925e-04,  2.9407e-04, -6.0512e-04, -2.2076e-04,  1.8555e-04,\n",
      "          1.2193e-03,  1.6992e-04, -5.9064e-04, -5.0956e-04,  9.8563e-05,\n",
      "          1.1295e-03, -1.1389e-03,  6.4075e-04,  1.2976e-03,  1.1254e-03,\n",
      "         -1.3407e-03],\n",
      "        [ 9.3698e-04,  6.3859e-04, -1.7300e-03, -1.4584e-03, -1.7385e-03,\n",
      "          7.0054e-04,  1.3573e-03,  2.3365e-04, -9.5502e-04, -7.4237e-04,\n",
      "         -1.4134e-04,  1.2118e-03, -6.8810e-04, -1.5875e-03,  9.3043e-04,\n",
      "         -3.4701e-04],\n",
      "        [-2.4087e-04,  7.2985e-04, -3.6349e-04, -5.2382e-04,  1.0123e-03,\n",
      "         -1.0009e-03, -2.3299e-03, -5.7165e-04, -3.8791e-04, -1.6578e-04,\n",
      "          3.9468e-04, -2.5282e-03,  1.1554e-03, -1.4329e-03, -2.4020e-03,\n",
      "          7.0328e-04],\n",
      "        [ 6.9418e-04,  8.0016e-04,  4.3916e-04, -7.2676e-04, -7.1955e-04,\n",
      "          1.6464e-03, -8.9305e-04, -7.1133e-04,  9.7570e-04, -2.7191e-04,\n",
      "         -7.2680e-05, -4.5711e-04, -1.4884e-04, -1.3322e-03, -4.5413e-06,\n",
      "          1.5104e-04],\n",
      "        [-3.6688e-05, -2.8693e-04,  1.9037e-03,  2.0492e-03, -8.3714e-04,\n",
      "          4.2015e-05,  8.2651e-04,  3.0756e-04,  4.7367e-05, -1.4716e-03,\n",
      "         -3.7899e-04,  2.6174e-04,  5.8711e-04, -1.9398e-04,  4.2219e-04,\n",
      "         -1.2733e-03],\n",
      "        [ 1.0562e-03,  6.5110e-04,  7.1544e-05,  6.8877e-04, -2.5482e-04,\n",
      "          2.1474e-03,  2.6250e-04, -4.5545e-04, -1.0154e-03,  1.2016e-03,\n",
      "          1.9143e-04,  7.1133e-04,  3.3163e-04,  2.1431e-04, -1.1182e-03,\n",
      "         -2.5722e-04],\n",
      "        [ 2.3123e-03,  7.4397e-04, -1.2858e-03, -5.3521e-04,  2.2794e-04,\n",
      "          6.8411e-04,  2.9224e-04,  2.3627e-04, -2.0730e-03, -4.2261e-05,\n",
      "          2.1616e-03, -5.7267e-05, -1.1739e-03, -7.2669e-04, -5.9348e-04,\n",
      "          9.7649e-04],\n",
      "        [-1.1232e-03, -1.0812e-03,  1.1841e-03, -7.9907e-04, -5.4125e-04,\n",
      "          4.6705e-04, -1.2396e-03, -1.2611e-03,  3.1655e-04, -1.1149e-03,\n",
      "         -2.5769e-04,  3.4358e-04,  1.2994e-04,  1.8576e-03, -1.8612e-04,\n",
      "         -1.5473e-05],\n",
      "        [-1.6184e-03, -3.6028e-04, -2.7471e-03, -1.1941e-03,  1.0842e-03,\n",
      "         -1.4576e-03,  8.0632e-04, -1.2037e-03, -1.7756e-03, -9.8686e-04,\n",
      "          1.7346e-03,  3.7462e-04,  1.2693e-03, -5.9432e-04,  2.1641e-04,\n",
      "         -1.4592e-03],\n",
      "        [ 2.1321e-03, -4.6871e-04, -8.9372e-04, -3.7479e-04, -9.4192e-05,\n",
      "         -1.2015e-04,  1.4323e-04,  5.0592e-04,  6.9457e-04, -4.9967e-04,\n",
      "          6.5550e-05,  2.0103e-03, -1.4597e-04, -1.0186e-03, -7.5217e-04,\n",
      "         -4.4276e-04],\n",
      "        [ 9.0006e-04, -1.0257e-03,  3.7196e-04, -1.2086e-03, -1.6979e-04,\n",
      "          5.7189e-04, -3.8157e-04,  3.3758e-04,  1.1291e-03,  6.9758e-04,\n",
      "         -1.6900e-03, -9.9800e-04,  1.5754e-03,  9.6231e-04, -1.2960e-03,\n",
      "          5.3839e-05],\n",
      "        [-1.7782e-03,  6.8131e-05, -1.7668e-03, -7.2993e-04, -2.9292e-04,\n",
      "          1.8468e-03,  5.4295e-05, -3.2895e-04,  7.1814e-04, -2.1979e-03,\n",
      "          8.2540e-04,  2.3159e-03,  7.2586e-04,  9.1444e-04,  1.2343e-04,\n",
      "          1.1288e-03]], requires_grad=True), Parameter containing:\n",
      "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-1.3334e-03,  8.4639e-04,  1.1066e-03, -3.1140e-05, -9.6186e-04,\n",
      "          2.7550e-04,  1.1157e-03, -1.4540e-03, -1.6585e-03, -7.3074e-04,\n",
      "         -9.5391e-04, -6.7915e-04, -2.9560e-04, -1.1830e-03,  1.5561e-04,\n",
      "         -1.0979e-03],\n",
      "        [ 1.1246e-03,  2.2365e-03, -1.3630e-03, -2.9626e-04, -1.2071e-03,\n",
      "          3.3956e-04, -5.0248e-04, -1.1610e-03, -2.1989e-03, -1.9364e-04,\n",
      "         -1.3528e-03,  5.8596e-04, -2.0548e-04, -1.9118e-04, -1.7473e-03,\n",
      "         -1.2486e-03],\n",
      "        [ 7.8886e-05, -7.0038e-04,  5.6062e-04, -6.7652e-05, -7.6066e-04,\n",
      "         -8.7898e-04, -3.7223e-05,  8.8958e-04, -1.2525e-04, -2.0389e-04,\n",
      "         -8.8383e-04,  1.5938e-03,  9.7545e-04,  1.5642e-03,  6.7449e-04,\n",
      "         -1.2395e-03],\n",
      "        [ 9.2691e-04, -3.6149e-04, -7.4699e-04, -2.1344e-03, -9.0399e-04,\n",
      "         -6.8205e-04,  3.3361e-04, -4.2982e-04,  7.7511e-04,  1.7317e-04,\n",
      "         -5.8061e-04,  1.8352e-03, -1.1319e-03,  6.2174e-04, -1.8588e-03,\n",
      "         -1.5666e-03],\n",
      "        [-5.6956e-04, -5.3890e-04, -8.2476e-04, -1.1166e-03,  1.0968e-03,\n",
      "         -1.9466e-03,  1.0811e-03, -5.8225e-04,  2.5234e-05, -1.3763e-03,\n",
      "         -6.3534e-04, -8.4444e-04,  2.3586e-03,  4.3131e-04,  1.9420e-03,\n",
      "          4.1171e-04],\n",
      "        [ 1.8151e-03, -4.2758e-04, -7.4148e-04, -1.5662e-03, -3.0898e-04,\n",
      "          3.4251e-04, -1.0634e-03,  6.4866e-04, -1.0555e-03,  7.8400e-04,\n",
      "         -2.9012e-05,  1.2978e-03,  3.2359e-04, -1.1114e-03,  1.0738e-03,\n",
      "         -2.2417e-04],\n",
      "        [ 9.1697e-04, -1.3518e-03,  6.0716e-04, -6.3461e-05, -7.5484e-04,\n",
      "         -7.1534e-04, -1.3301e-03,  1.7936e-03,  1.4079e-03, -2.6703e-03,\n",
      "         -3.6213e-04, -1.8784e-04,  1.1223e-03, -1.2773e-04, -5.2971e-04,\n",
      "          6.7428e-04],\n",
      "        [ 9.0613e-04, -4.4341e-04,  1.4326e-03, -1.4732e-03, -8.9999e-04,\n",
      "          5.0642e-04,  1.4129e-03, -1.1017e-03,  1.4600e-03, -3.4396e-04,\n",
      "         -8.4988e-04,  4.1704e-04,  5.6041e-04, -5.0223e-04, -3.7638e-04,\n",
      "         -1.2097e-03],\n",
      "        [ 7.3956e-04,  4.2097e-04, -1.0771e-03, -2.0910e-04,  1.0097e-03,\n",
      "         -4.4591e-04, -3.0579e-04, -7.7544e-04,  5.2279e-04, -2.9768e-04,\n",
      "          9.2990e-06,  4.8441e-04,  3.9753e-05,  9.9016e-04,  4.6545e-04,\n",
      "         -8.4851e-04],\n",
      "        [-8.4102e-05,  2.3305e-03,  3.9206e-04, -2.0154e-03, -3.9820e-04,\n",
      "         -1.3112e-03,  6.6017e-04, -8.1038e-04,  1.1611e-04,  1.0353e-03,\n",
      "          1.6267e-04, -7.7049e-04, -1.2603e-04,  1.4904e-03,  2.2435e-04,\n",
      "         -1.6044e-03],\n",
      "        [ 7.0018e-04,  7.5808e-04,  7.0002e-04,  6.4462e-04,  1.1519e-03,\n",
      "         -2.4550e-03, -8.0145e-04, -3.1172e-04,  4.5418e-04,  3.6206e-04,\n",
      "         -1.2528e-03, -1.4429e-04, -1.9139e-04, -8.1037e-04, -6.0907e-04,\n",
      "          1.0323e-03],\n",
      "        [ 7.7753e-04, -3.6379e-04,  8.9479e-05, -7.7651e-04, -1.2120e-04,\n",
      "          5.6455e-04, -4.3911e-04, -3.4733e-04,  8.6249e-04,  7.7608e-04,\n",
      "          1.3132e-03, -6.2312e-04, -1.3496e-03,  1.4005e-03,  7.8577e-04,\n",
      "          1.1484e-03],\n",
      "        [-2.1100e-03,  8.5516e-04,  9.3345e-04,  1.4265e-03,  3.3357e-04,\n",
      "         -4.7071e-04,  1.7822e-03,  1.4057e-03, -4.0233e-04, -1.1201e-03,\n",
      "         -4.6048e-04,  1.6234e-04, -1.0368e-03, -2.1080e-04, -8.3230e-04,\n",
      "          1.5818e-03],\n",
      "        [ 7.1383e-04, -2.1135e-03,  3.9551e-04,  6.0731e-05,  4.5881e-04,\n",
      "         -2.0625e-04, -7.2908e-04, -1.9270e-03,  9.6582e-04,  8.9494e-04,\n",
      "          3.4167e-04, -1.5481e-03, -1.6025e-03, -1.4104e-03,  1.1673e-03,\n",
      "         -1.6429e-04],\n",
      "        [ 6.2907e-04, -2.6105e-04, -3.2018e-04,  1.3774e-03,  1.0300e-03,\n",
      "          7.0871e-04, -6.1626e-04,  1.0859e-03, -3.0982e-04, -6.8494e-04,\n",
      "          1.6237e-04, -2.4786e-03,  1.0573e-03, -1.0811e-03, -1.3437e-04,\n",
      "          3.5250e-04],\n",
      "        [ 7.7771e-04, -4.4417e-06, -9.0118e-07, -1.0117e-03,  1.4071e-03,\n",
      "          7.6712e-04, -1.2929e-03,  1.1159e-03, -1.1978e-03,  1.0762e-03,\n",
      "         -1.8719e-04, -1.2639e-03,  1.1469e-03,  5.3383e-04,  1.3939e-03,\n",
      "          8.9354e-04]], requires_grad=True), Parameter containing:\n",
      "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 2.0684e-03,  2.3579e-04,  7.0717e-04,  2.5968e-04,  1.2439e-03,\n",
      "          8.7801e-04,  8.3746e-04, -2.3634e-03,  1.1784e-04,  1.0610e-03,\n",
      "          4.0056e-04,  3.7702e-04,  4.7935e-04, -3.3876e-04, -1.6227e-06,\n",
      "          5.8352e-04],\n",
      "        [ 2.0482e-04,  8.5106e-06,  3.5391e-04, -5.0534e-04,  3.4945e-04,\n",
      "         -1.5276e-03,  1.0762e-04,  8.1880e-04,  4.5339e-04, -3.9652e-04,\n",
      "          7.4356e-04,  8.4894e-04,  1.0150e-03,  5.5493e-04,  1.7537e-03,\n",
      "          1.2021e-03],\n",
      "        [-2.8438e-05,  1.6096e-03, -8.7418e-04, -4.8029e-04, -3.9312e-05,\n",
      "          7.6596e-04, -2.8933e-04, -1.7490e-03,  2.9766e-04, -7.9496e-04,\n",
      "         -3.3231e-04,  3.8091e-05,  4.7026e-04,  4.6620e-05,  2.1622e-03,\n",
      "          5.7092e-04],\n",
      "        [ 7.9407e-04, -8.3831e-05,  2.2818e-04,  1.0914e-04, -1.8378e-04,\n",
      "          1.1473e-03, -2.4844e-04,  6.0675e-05, -3.4968e-04,  1.8732e-03,\n",
      "         -3.5425e-04,  1.4886e-04,  8.2967e-05,  1.4212e-03,  2.1742e-04,\n",
      "          1.4555e-03],\n",
      "        [-5.4350e-04,  2.6617e-03, -2.1721e-03, -4.7658e-04, -4.0748e-04,\n",
      "          8.1318e-04, -1.6897e-03, -2.2975e-04, -2.1339e-04,  1.4977e-03,\n",
      "          4.0230e-04,  1.2131e-03,  1.7513e-03, -5.5464e-04,  8.0105e-04,\n",
      "         -6.2596e-04],\n",
      "        [ 7.4285e-04, -1.1293e-04, -1.7020e-03, -5.2733e-04, -2.0154e-04,\n",
      "         -5.2718e-05, -1.3817e-04,  6.8108e-04, -1.3690e-04, -1.0105e-03,\n",
      "          7.6354e-05, -2.4913e-03, -4.3752e-04,  5.7447e-04, -1.0537e-03,\n",
      "          1.1935e-03]], requires_grad=True), Parameter containing:\n",
      "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(ode_func.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80046ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|#########################################| 656/656 [01:57<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([[0.0360, 0.0369, 0.0367, 0.0368, 0.0363, 0.0366]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "var: tensor([[-0.0019,  0.0001,  0.0015,  0.0007,  0.0014,  0.0003]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "z0: tensor([[9.1603e+02, 3.6786e-02, 3.6134e-02, 3.6991e-02, 3.4940e-02, 3.6436e-02]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "sol: tensor([[[9.1603e+02, 3.6786e-02, 3.6134e-02, 3.6991e-02, 3.4940e-02,\n",
      "          3.6436e-02]],\n",
      "\n",
      "        [[9.2049e+02, 4.5349e+00, 4.5320e+00, 4.5377e+00, 4.5143e+00,\n",
      "          4.5260e+00]]], grad_fn=<OdeintAdjointMethodBackward>)\n",
      "solves: tensor([[[3.1751e-02, 3.6786e-02, 3.6134e-02, 3.6991e-02, 3.4940e-02,\n",
      "          3.6436e-02]],\n",
      "\n",
      "        [[3.0067e+02, 6.7943e-01, 6.7845e-01, 6.8000e-01, 6.7490e-01,\n",
      "          6.7786e-01]],\n",
      "\n",
      "        [[3.0449e+02, 4.5353e+00, 4.5324e+00, 4.5381e+00, 4.5147e+00,\n",
      "          4.5264e+00]],\n",
      "\n",
      "        [[3.0449e+02, 4.5353e+00, 4.5324e+00, 4.5381e+00, 4.5147e+00,\n",
      "          4.5264e+00]],\n",
      "\n",
      "        [[3.0385e+02, 3.8927e+00, 3.8900e+00, 3.8950e+00, 3.8747e+00,\n",
      "          3.8850e+00]],\n",
      "\n",
      "        [[6.0867e+02, 6.7941e-01, 6.7843e-01, 6.7998e-01, 6.7488e-01,\n",
      "          6.7784e-01]],\n",
      "\n",
      "        [[6.1249e+02, 4.5351e+00, 4.5322e+00, 4.5379e+00, 4.5145e+00,\n",
      "          4.5263e+00]],\n",
      "\n",
      "        [[6.1249e+02, 4.5351e+00, 4.5322e+00, 4.5379e+00, 4.5145e+00,\n",
      "          4.5263e+00]],\n",
      "\n",
      "        [[6.1185e+02, 3.8925e+00, 3.8899e+00, 3.8949e+00, 3.8746e+00,\n",
      "          3.8848e+00]],\n",
      "\n",
      "        [[9.1667e+02, 6.7938e-01, 6.7840e-01, 6.7995e-01, 6.7485e-01,\n",
      "          6.7781e-01]],\n",
      "\n",
      "        [[9.2049e+02, 4.5349e+00, 4.5320e+00, 4.5377e+00, 4.5143e+00,\n",
      "          4.5260e+00]],\n",
      "\n",
      "        [[9.2049e+02, 4.5349e+00, 4.5320e+00, 4.5377e+00, 4.5143e+00,\n",
      "          4.5260e+00]]], grad_fn=<CatBackward0>)\n",
      "idx: tensor([[[True],\n",
      "         [True],\n",
      "         [True],\n",
      "         [True],\n",
      "         [True],\n",
      "         [True],\n",
      "         [True],\n",
      "         [True],\n",
      "         [True],\n",
      "         [True],\n",
      "         [True],\n",
      "         [True]]])\n",
      "Preds: tensor([ 2.6601,  6.3402,  6.5961,  6.5961,  6.5535,  9.9150, 10.1707, 10.1707,\n",
      "        10.1281, 13.4883, 13.7440, 13.7440], grad_fn=<IndexBackward0>)\n",
      "Labels: tensor([ 4.7756, 60.3880, 16.0390,  4.5623,  1.5531, 62.9590, 16.7740,  4.7714,\n",
      "         1.6243, 63.0070, 16.7890,  4.7756])\n",
      "rmse: 31.607763\n",
      "train_loss: 24.056007\n",
      "val_loss: 31.607763\n"
     ]
    }
   ],
   "source": [
    "#ran 1 epochs for testing purposes\n",
    "for epoch in range(1):\n",
    "\n",
    "    for _ in tqdm(range(batches_per_epoch), ascii=True):\n",
    "        #sets gradients of all parameters to zero. This prevents the incorrect accumulation of gradients that occurs if you call loss.backwards more than once wihtout zeroing out the gradients.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #extracts training features and dosing\n",
    "        ptnms, times, features, labels, cmax_time = tdm1_obj[\"train_dataloader\"].__next__()\n",
    "        dosing = torch.zeros([features.size(0), features.size(1), latent_dim])\n",
    "        dosing[:, :, 0] = features[:, :, -2]\n",
    "        dosing = dosing.permute(1, 0, 2)\n",
    "\n",
    "        #VAE concept used here. We are taking the output of the encoder and sampling z_0 from a distribution of the latent space variables gathered from estimating the mean and variance from the 12 elements outputted by the encoder. \n",
    "        encoder_out = encoder(features)\n",
    "        qz0_mean, qz0_var = encoder_out[:, :latent_dim], encoder_out[:, latent_dim:]\n",
    "        z0 = utils.sample_standard_gaussian(qz0_mean, qz0_var)\n",
    "        \n",
    "        solves = z0.unsqueeze(0).clone()\n",
    "        try:\n",
    "            #this is where the idea of neural-ODE's are used. dosing information and time interval are incorporated into the event from the previous time step. The time interval from the previous time interval and z_i-1 are sent into the ODE Solver function.\n",
    "            for idx, (time0, time1) in enumerate(zip(times[:-1], times[1:])):\n",
    "                z0 += dosing[idx]\n",
    "                time_interval = torch.Tensor([time0 - time0, time1 - time0])\n",
    "                #ODE Solver function: feeds through ode_func to generate z_ti and then integrates with dosing info\n",
    "                sol = odeint(ode_func, z0, time_interval, rtol=1e-4, atol=1e-4)\n",
    "                #z0 = sol[-1].clone()\n",
    "                #running sequence of all z_i's at each time step which will eventially be used to predict output in the decoder\n",
    "                solves = torch.cat([solves, sol[-1:, :]], 0)\n",
    "        except AssertionError:\n",
    "            print(times)\n",
    "            print(time0, time1, time_interval, ptnms)\n",
    "            continue\n",
    "\n",
    "        #prediction generation from sequence of z_i's\n",
    "        preds = classifier(solves, cmax_time)\n",
    "\n",
    "        # computes MSE on preds vs observations \n",
    "        loss = utils.compute_loss_on_train(criterion, labels, preds)\n",
    "        try: \n",
    "            #automatically computes gradients of loss tensor\n",
    "            loss.backward()\n",
    "        except RuntimeError:\n",
    "            print(ptnms)\n",
    "            print(times)\n",
    "            continue\n",
    "        #performs a single parameter update (single optimization step)\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"mean: \" + str(qz0_mean))\n",
    "    print(\"var: \" + str(qz0_var))\n",
    "    print(\"z0: \" + str(z0))\n",
    "    print(\"sol: \" + str(sol))\n",
    "    print(\"solves: \" + str(solves))\n",
    "    idx_not_nan = ~(torch.isnan(labels) | (labels == -1))\n",
    "    print(\"idx: \" + str(idx_not_nan))\n",
    "    preds = preds.permute(1, 0, 2)[idx_not_nan]\n",
    "    labels = labels[idx_not_nan]\n",
    "    print(\"Preds: \" + str(preds))\n",
    "    print(\"Labels: \" + str(labels))\n",
    "\n",
    "    #torch.no_grad() is used to prevent the automatic calculation of gradients to clearly see unbiased training/validation error \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        #training error\n",
    "        train_res = utils.compute_loss_on_test(encoder, ode_func, classifier, args,\n",
    "            tdm1_obj[\"train_dataloader\"], tdm1_obj[\"n_train_batches\"], \n",
    "            device, phase=\"train\")\n",
    "\n",
    "        #validation error\n",
    "        validation_res = utils.compute_loss_on_test(encoder, ode_func, classifier, args,\n",
    "            tdm1_obj[\"val_dataloader\"], tdm1_obj[\"n_val_batches\"], \n",
    "            device, phase=\"validate\")\n",
    "        \n",
    "        train_loss = train_res[\"loss\"] \n",
    "        validation_loss = validation_res[\"loss\"]\n",
    "\n",
    "        #if the validation loss on the current interation is better than the best running RMSE, then we save the weights and biases of the encoder, ode, classifier, and arguments\n",
    "        #if validation_loss < best_rmse:\n",
    "         #   torch.save({'encoder': encoder.state_dict(),\n",
    "          #              'ode': ode_func.state_dict(),\n",
    "           #             'classifier': classifier.state_dict(),\n",
    "            #            'args': args}, ckpt_path)\n",
    "        best_rmse = validation_loss\n",
    "        best_epochs = epoch\n",
    "\n",
    "print(\"rmse: \" + str(best_rmse))\n",
    "print(\"train_loss: \" + str(train_loss))\n",
    "print(\"val_loss: \" + str(validation_loss))\n",
    "        #message = \"\"\"\n",
    "        #Epoch {:04d} | Training loss {:.6f} | Training R2 {:.6f} | Validation loss {:.6f} | Validation R2 {:.6f}\n",
    "        #Best loss {:.6f} | Best epoch {:04d}\n",
    "        #\"\"\".format(epoch, train_loss, train_res[\"r2\"], validation_loss, validation_res[\"r2\"], best_rmse, best_epochs)\n",
    "        #logger.info(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e36a4b",
   "metadata": {},
   "source": [
    "## run_predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f96513f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d3/_4zxml3949n9w23hrq3ngqrm0000gn/T/ipykernel_85843/2318606238.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m#uses compute loss on interpolated data. Interpolated data contains estimated \"intermediate\" values between data points to smooth out the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     test_res = utils.compute_loss_on_interp(encoder, ode_func, classifier, args,\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mtdm1_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"interp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtdm1_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_dataloader\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtdm1_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_test_batches\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         device, phase=\"test\")\n",
      "\u001b[0;32m~/Desktop/DL_PKPD_Project/DL-PK-PD/SupplementaryCode/cross-schedule_models/Neural-ODE/utils.py\u001b[0m in \u001b[0;36mcompute_loss_on_interp\u001b[0;34m(encoder, ode_func, classifier, args, dataloader, dataloader_o, n_batches, device, phase)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mptnm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmax_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mptnm_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_o\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmax_time_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader_o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mptnm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mptnm_o\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_PKPD_Project/DL-PK-PD/SupplementaryCode/cross-schedule_models/Neural-ODE/utils.py\u001b[0m in \u001b[0;36minf_generator\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0midx_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_in_batch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0midx_in_batch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DL_PKPD_Project/DL-PK-PD/SupplementaryCode/cross-schedule_models/Neural-ODE/data_parse.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPTNM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5572\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5573\u001b[0m         ):\n\u001b[0;32m-> 5574\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5575\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3469\u001b[0m             \u001b[0;31m# is_iterator to exclude generator e.g. test_getitem_listlike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3470\u001b[0m             \u001b[0;31m# shortcut if the key is in columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3471\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3472\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3473\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#parses input data into feature columns, etc.\n",
    "tdm1_obj = parse_tdm1(device, phase=\"test\")\n",
    "input_dim = tdm1_obj[\"input_dim\"]\n",
    "#represents hidden units of GRU in encoder\n",
    "hidden_dim = 128 \n",
    "latent_dim = 6\n",
    "\n",
    "#instantiates encoder. Output dimension is 12 because 6 elements are used to determine the value of the mean for the distribution of the latent space while the other 6 are used to estimate the variance.\n",
    "encoder = Encoder(input_dim=input_dim, output_dim=2 * latent_dim, hidden_dim=hidden_dim)\n",
    "#instantiates governing ODEFunc\n",
    "ode_func = ODEFunc(input_dim=latent_dim, hidden_dim=16)\n",
    "#instantiates decoder\n",
    "classifier = Classifier(latent_dim=latent_dim, output_dim=1)\n",
    "\n",
    "#loads the model's parameter dictionary\n",
    "#utils.load_model(ckpt_path, encoder, ode_func, classifier, device)\n",
    "\n",
    "########################################################################\n",
    "## Predict & Evaluate\n",
    "#disables gradient calculation, allowing for less memory consumption and faster compute. It is generally used to perform validation/testing because gradients are not required to be computed when testing model performance.\n",
    "with torch.no_grad():\n",
    "    #uses compute loss on test\n",
    "    #the function compute_loss_ is where the ODE solver functions integrate the dosing info and time interval. This is also where the concept of VAE's are used where z_0 is sampled from the latent distribution (which is derived from the mean and variance calculated by the 12 element input array). see page 6 of paper for more specific info. \n",
    "    test_res = utils.compute_loss_on_test(encoder, ode_func, classifier, args,\n",
    "        tdm1_obj[\"test_dataloader\"], tdm1_obj[\"n_test_batches\"], \n",
    "        device, phase=\"test\")\n",
    "\n",
    "eval_results = pd.DataFrame(test_res).drop(columns=\"loss\")\n",
    "#eval_results.to_csv(eval_path, index=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    #uses compute loss on interpolated data. Interpolated data contains estimated \"intermediate\" values between data points to smooth out the data\n",
    "    test_res = utils.compute_loss_on_interp(encoder, ode_func, classifier, args,\n",
    "        tdm1_obj[\"interp\"], tdm1_obj[\"test_dataloader\"], tdm1_obj[\"n_test_batches\"], \n",
    "        device, phase=\"test\")\n",
    "\n",
    "#puts results in a data frame and migrates to csv file\n",
    "eval_results = pd.DataFrame(test_res).drop(columns=\"loss\")\n",
    "#eval_results.to_csv(eval_path + \".interp\", index=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    #uses compute loss on interpolated data without dosing info\n",
    "    test_res = utils.compute_loss_on_interp(encoder, ode_func, classifier, args,\n",
    "        tdm1_obj[\"nodosing\"], tdm1_obj[\"test_dataloader\"], tdm1_obj[\"n_test_batches\"], \n",
    "        device, phase=\"test\")\n",
    "\n",
    "eval_results = pd.DataFrame(test_res).drop(columns=\"loss\")\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e55cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
