{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import SystemRandom\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchdiffeq import odeint_adjoint as odeint\n",
    "# from torch.nn.modules.rnn import GRU, LSTM, RNN\n",
    "\n",
    "import utils\n",
    "from args import args\n",
    "from data_parse import parse_tdm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEFunc(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(ODEFunc, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(hidden_dim, input_dim)\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.001)\n",
    "                nn.init.constant_(m.bias, val=0.5)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        # print(x)\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, device=torch.device(\"cpu\")):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "\n",
    "        self.hiddens_to_output = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim),\n",
    "        )\n",
    "        utils.init_network_weights(self.hiddens_to_output, std=0.001)\n",
    "\n",
    "        # self.rnn = nn.RNN(self.input_dim, self.hidden_dim, nonlinearity=\"relu\").to(device)\n",
    "        self.rnn = nn.GRU(self.input_dim, self.hidden_dim).to(device)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.permute(1, 0, 2)\n",
    "        data = utils.reverse(data)\n",
    "        output_rnn, _ = self.rnn(data)\n",
    "        #print(output_rnn)\n",
    "        outputs = self.hiddens_to_output(output_rnn[-1])\n",
    "        #print(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mClassifier\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, latent_dim, output_dim):\n\u001b[1;32m      4\u001b[0m         \u001b[39msuper\u001b[39m(Classifier, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim + 20, 32),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(32, output_dim),\n",
    "        )\n",
    "        \n",
    "        utils.init_network_weights(self.net, std=0.001)\n",
    "\n",
    "    def forward(self, z, cmax_time):\n",
    "        cmax_time = cmax_time.repeat(z.size(0), 1, 1)\n",
    "        z = torch.cat([z, cmax_time], 2)\n",
    "        return self.net(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# file_name = os.path.basename(__file__)[:-3]\n",
    "utils.makedirs(args.save)\n",
    "\n",
    "input_cmd = sys.argv\n",
    "input_cmd = \" \".join(input_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.random_seed + args.model + args.fold)\n",
    "np.random.seed(args.random_seed + args.model + args.fold)\n",
    "\n",
    "ckpt_path = os.path.join(args.save, f\"fold_{args.fold}_model_{args.model}.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm1_obj = parse_tdm1(device, phase=\"train\")\n",
    "input_dim = tdm1_obj[\"input_dim\"]\n",
    "hidden_dim = 128\n",
    "latent_dim = 6\n",
    "\n",
    "encoder = Encoder(input_dim=input_dim, output_dim=2 * latent_dim, hidden_dim=hidden_dim)\n",
    "ode_func = ODEFunc(input_dim=latent_dim, hidden_dim=16)\n",
    "classifier = Classifier(latent_dim=latent_dim, output_dim=1)\n",
    "\n",
    "\n",
    "if args.continue_train:\n",
    "    utils.load_model(ckpt_path, encoder, ode_func, classifier, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"logs/\" + f\"fold_{args.fold}_model_{args.model}.log\"\n",
    "utils.makedirs(\"logs/\")\n",
    "logger = utils.get_logger(logpath=log_path, filepath=os.path.abspath(__file__))\n",
    "logger.info(input_cmd)\n",
    "\n",
    "batches_per_epoch = tdm1_obj[\"n_train_batches\"]\n",
    "criterion = nn.MSELoss().to(device=device)\n",
    "params = (list(encoder.parameters()) + \n",
    "          list(ode_func.parameters()) + \n",
    "          list(classifier.parameters()))\n",
    "optimizer = optim.Adam(params, lr=args.lr, weight_decay=args.l2)\n",
    "best_rmse = 0x7fffffff\n",
    "best_epochs = 0\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "\n",
    "    for _ in tqdm(range(batches_per_epoch), ascii=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ptnms, times, features, labels, cmax_time = tdm1_obj[\"train_dataloader\"].__next__()\n",
    "        dosing = torch.zeros([features.size(0), features.size(1), latent_dim])\n",
    "        dosing[:, :, 0] = features[:, :, -2]\n",
    "        dosing = dosing.permute(1, 0, 2)\n",
    "\n",
    "        encoder_out = encoder(features)\n",
    "        qz0_mean, qz0_var = encoder_out[:, :latent_dim], encoder_out[:, latent_dim:]\n",
    "        z0 = utils.sample_standard_gaussian(qz0_mean, qz0_var)\n",
    "        \n",
    "        solves = z0.unsqueeze(0).clone()\n",
    "        try:\n",
    "            for idx, (time0, time1) in enumerate(zip(times[:-1], times[1:])):\n",
    "                z0 += dosing[idx]\n",
    "                time_interval = torch.Tensor([time0 - time0, time1 - time0])\n",
    "                sol = odeint(ode_func, z0, time_interval, rtol=args.tol, atol=args.tol)\n",
    "                z0 = sol[-1].clone()\n",
    "                solves = torch.cat([solves, sol[-1:, :]], 0)\n",
    "        except AssertionError:\n",
    "            print(times)\n",
    "            print(time0, time1, time_interval, ptnms)\n",
    "            continue\n",
    "    \n",
    "        preds = classifier(solves, cmax_time)\n",
    "\n",
    "        loss = utils.compute_loss_on_train(criterion, labels, preds)\n",
    "        try: \n",
    "            loss.backward()\n",
    "        except RuntimeError:\n",
    "            print(ptnms)\n",
    "            print(times)\n",
    "            continue\n",
    "        optimizer.step()\n",
    "    \n",
    "    idx_not_nan = ~(torch.isnan(labels) | (labels == -1))\n",
    "    preds = preds.permute(1, 0, 2)[idx_not_nan]\n",
    "    labels = labels[idx_not_nan]\n",
    "    print(preds)\n",
    "    print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        \n",
    "        train_res = utils.compute_loss_on_test(encoder, ode_func, classifier, args,\n",
    "            tdm1_obj[\"train_dataloader\"], tdm1_obj[\"n_train_batches\"], \n",
    "            device, phase=\"train\")\n",
    "\n",
    "        validation_res = utils.compute_loss_on_test(encoder, ode_func, classifier, args,\n",
    "            tdm1_obj[\"val_dataloader\"], tdm1_obj[\"n_val_batches\"], \n",
    "            device, phase=\"validate\")\n",
    "        \n",
    "        train_loss = train_res[\"loss\"] \n",
    "        validation_loss = validation_res[\"loss\"]\n",
    "        if validation_loss < best_rmse:\n",
    "            torch.save({'encoder': encoder.state_dict(),\n",
    "                        'ode': ode_func.state_dict(),\n",
    "                        'classifier': classifier.state_dict(),\n",
    "                        'args': args}, ckpt_path)\n",
    "            best_rmse = validation_loss\n",
    "            best_epochs = epoch\n",
    "\n",
    "        message = \"\"\"\n",
    "        Epoch {:04d} | Training loss {:.6f} | Training R2 {:.6f} | Validation loss {:.6f} | Validation R2 {:.6f}\n",
    "        Best loss {:.6f} | Best epoch {:04d}\n",
    "        \"\"\".format(epoch, train_loss, train_res[\"r2\"], validation_loss, validation_res[\"r2\"], best_rmse, best_epochs)\n",
    "        logger.info(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "###############################################################\n",
    "## Main runnings\n",
    "ckpt_path = os.path.join(args.save, f\"fold_{args.fold}_model_{args.model}.ckpt\")\n",
    "eval_path = os.path.join(args.save, f\"fold_{args.fold}_model_{args.model}.csv\")\n",
    "res_path = \"rmse.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdm1_obj = parse_tdm1(device, phase=\"test\")\n",
    "input_dim = tdm1_obj[\"input_dim\"]\n",
    "hidden_dim = 128 \n",
    "latent_dim = 6\n",
    "\n",
    "encoder = Encoder(input_dim=input_dim, output_dim=2 * latent_dim, hidden_dim=hidden_dim)\n",
    "ode_func = ODEFunc(input_dim=latent_dim, hidden_dim=16)\n",
    "classifier = Classifier(latent_dim=latent_dim, output_dim=1)\n",
    "\n",
    "utils.load_model(ckpt_path, encoder, ode_func, classifier, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict & Evaluate\n",
    "with torch.no_grad():\n",
    "    test_res = utils.compute_loss_on_test(encoder, ode_func, classifier, args,\n",
    "        tdm1_obj[\"test_dataloader\"], tdm1_obj[\"n_test_batches\"], \n",
    "        device, phase=\"test\")\n",
    "\n",
    "eval_results = pd.DataFrame(test_res).drop(columns=\"loss\")\n",
    "eval_results.to_csv(eval_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
